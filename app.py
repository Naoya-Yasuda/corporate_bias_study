#!/usr/bin/env python
# coding: utf-8

"""
ä¼æ¥­ãƒã‚¤ã‚¢ã‚¹åˆ†æ - ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

Streamlitã‚’ä½¿ç”¨ã—ã¦ã€ä¼æ¥­ãƒã‚¤ã‚¢ã‚¹åˆ†æã®çµæœãƒ‡ãƒ¼ã‚¿ã‚’å¯è¦–åŒ–ã™ã‚‹ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ã™ã€‚
å‹•çš„å¯è¦–åŒ–ã‚·ã‚¹ãƒ†ãƒ ï¼šäº‹å‰ç”Ÿæˆç”»åƒã§ã¯ãªãã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ
"""

import os
import json
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from datetime import datetime
from dotenv import load_dotenv
from src.utils.storage_utils import get_s3_client, S3_BUCKET_NAME, get_latest_file, load_json
from src.utils.plot_utils import draw_reliability_badge
import numpy as np
from src.analysis.hybrid_data_loader import HybridDataLoader
import sys
import argparse

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆæœ€åˆã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰
import japanize_matplotlib

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# japanize_matplotlibã§æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’è‡ªå‹•è¨­å®š
# japanize_matplotlibãŒæ—¢ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€è‡ªå‹•çš„ã«æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãŒè¨­å®šã•ã‚Œã‚‹
# ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®è¨­å®š
try:
    font_path = '/System/Library/Fonts/ãƒ’ãƒ©ã‚®ãƒè§’ã‚´ã‚·ãƒƒã‚¯ W3.ttc'
    if os.path.exists(font_path):
        prop = fm.FontProperties(fname=font_path)
        plt.rcParams['font.family'] = prop.get_name()
        plt.rcParams['font.sans-serif'] = [prop.get_name()]
    else:
        # japanize_matplotlibã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨
        plt.rcParams['font.family'] = 'IPAexGothic'
except:
    # ã‚¨ãƒ©ãƒ¼æ™‚ã¯japanize_matplotlibã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨
    plt.rcParams['font.family'] = 'IPAexGothic'

plt.rcParams['axes.unicode_minus'] = False

# ã‚°ãƒ©ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
def set_plot_style():
    plt.style.use('seaborn-v0_8-whitegrid')
    plt.rcParams['figure.figsize'] = (6, 3)  # ã‚°ãƒ©ãƒ•ã‚µã‚¤ã‚ºã‚’ã•ã‚‰ã«å°ã•ãè¨­å®š
    plt.rcParams['font.size'] = 9
    plt.rcParams['axes.labelsize'] = 10
    plt.rcParams['axes.titlesize'] = 12
    plt.rcParams['xtick.labelsize'] = 8
    plt.rcParams['ytick.labelsize'] = 8
    plt.rcParams['legend.fontsize'] = 8
    plt.rcParams['figure.titlesize'] = 14
    plt.rcParams['axes.unicode_minus'] = False  # ãƒã‚¤ãƒŠã‚¹è¨˜å·ã‚’æ­£ã—ãè¡¨ç¤º

    # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã®ç¢ºèª
    if 'font.family' not in plt.rcParams or not plt.rcParams['font.family']:
        plt.rcParams['font.family'] = 'IPAexGothic'

# ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®šã‚’é©ç”¨
set_plot_style()

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ä¼æ¥­ãƒã‚¤ã‚¢ã‚¹åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# çµ±ä¸€ã•ã‚ŒãŸCSSè¨­å®š
st.markdown("""
<style>
    /* ãƒ¡ã‚¤ãƒ³ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚¨ãƒªã‚¢ã®æ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«è¨­å®š */
    .main-dashboard-area {
        width: calc(100vw - 336px - 32px);
        min-width: 600px;
        max-width: 100vw;
        overflow-x: auto;
        margin-left: 0;
        margin-right: 0;
        padding-bottom: 2rem;
    }

    /* ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š */
    body {
        font-family: 'Hiragino Sans', 'Meiryo', sans-serif;
    }

    /* ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã¨ã‚°ãƒ©ãƒ•ã®æ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ« */
    .stDataFrame, .stTable, .stPlotlyChart, .element-container {
        overflow-x: auto !important;
        max-width: 100vw;
    }
</style>
""", unsafe_allow_html=True)

# å‹•çš„å¯è¦–åŒ–é–¢æ•°ç¾¤
def plot_ranking_similarity(similarity_data, title):
    """ãƒ©ãƒ³ã‚­ãƒ³ã‚°é¡ä¼¼åº¦ã®å‹•çš„å¯è¦–åŒ–"""
    metrics = ['rbo_score', 'kendall_tau', 'overlap_ratio']
    values = [similarity_data.get(metric, 0) for metric in metrics]
    labels = ['RBO\n(ä¸Šä½é‡è¦–é‡è¤‡åº¦)', 'Kendall Tau\n(é †ä½ç›¸é–¢)', 'Overlap Ratio\n(å…±é€šè¦ç´ ç‡)']

    fig, ax = plt.subplots(figsize=(8, 6))  # ã‚µã‚¤ã‚ºã‚’èª¿æ•´
    bars = ax.bar(labels, values, alpha=0.7, color=['blue', 'orange', 'green'])
    ax.set_title(f"{title} - Google vs Perplexityé¡ä¼¼åº¦")
    ax.set_ylabel("é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢")
    ax.set_ylim(0, 1)

    # Xè»¸ãƒ©ãƒ™ãƒ«ã®å›è»¢ã¨ä½ç½®èª¿æ•´
    plt.xticks(rotation=0, ha='center')

    for bar, value in zip(bars, values):
        if value is not None:
            ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.02,
                    f'{value:.3f}', ha='center', va='bottom', fontweight='bold')

    # ã‚°ãƒªãƒƒãƒ‰è¿½åŠ 
    ax.grid(axis='y', alpha=0.3)
    plt.tight_layout()
    return fig

def plot_bias_indices_bar(bias_data, title, reliability_label=None):
    """æ„Ÿæƒ…ãƒã‚¤ã‚¢ã‚¹æŒ‡æ¨™ã®å‹•çš„å¯è¦–åŒ–"""
    entities = list(bias_data.keys())
    values = [bias_data[e] for e in entities]

    # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ•°ã«å¿œã˜ã¦ã‚µã‚¤ã‚ºã‚’èª¿æ•´
    if len(entities) > 10:
        fig, ax = plt.subplots(figsize=(12, 6))  # å¤šã„å ´åˆã¯æ¨ªã«åºƒã’ã‚‹
    else:
        fig, ax = plt.subplots(figsize=(8, 6))   # å°‘ãªã„å ´åˆã¯æ¨™æº–ã‚µã‚¤ã‚º

    bars = ax.bar(entities, values, color=["red" if v > 0 else "green" for v in values])
    ax.axhline(0, color='k', linestyle='--', alpha=0.5)
    ax.set_ylabel("Normalized Bias Index (BI)")
    ax.set_title(title)
    plt.xticks(rotation=30, ha="right")
    plt.tight_layout()

    # ä¿¡é ¼æ€§ãƒ©ãƒ™ãƒ«ã‚’è¿½åŠ 
    if reliability_label:
        draw_reliability_badge(ax, reliability_label)

    return fig

def plot_official_domain_comparison(official_data, title):
    """å…¬å¼ãƒ‰ãƒ¡ã‚¤ãƒ³æ¯”è¼ƒã®å‹•çš„å¯è¦–åŒ–"""
    google_ratio = official_data.get("google_official_ratio", 0)
    citations_ratio = official_data.get("citations_official_ratio", 0)

    fig, ax = plt.subplots(figsize=(6, 5))  # ã‚µã‚¤ã‚ºã‚’èª¿æ•´
    labels = ['Googleæ¤œç´¢', 'Perplexity Citations']
    values = [google_ratio, citations_ratio]
    colors = ['blue', 'orange']

    bars = ax.bar(labels, values, color=colors, alpha=0.7)
    ax.set_title(f"{title} - å…¬å¼ãƒ‰ãƒ¡ã‚¤ãƒ³ç‡æ¯”è¼ƒ")
    ax.set_ylabel("å…¬å¼ãƒ‰ãƒ¡ã‚¤ãƒ³ç‡")
    ax.set_ylim(0, 1)

    for bar, value in zip(bars, values):
        ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.02,
                f'{value:.3f}', ha='center', va='bottom', fontweight='bold')

    plt.tight_layout()
    return fig

def plot_sentiment_comparison(sentiment_data, title):
    """æ„Ÿæƒ…åˆ†ææ¯”è¼ƒã®å‹•çš„å¯è¦–åŒ–"""
    google_dist = sentiment_data.get("google_sentiment_distribution", {})
    citations_dist = sentiment_data.get("citations_sentiment_distribution", {})

    fig, ax = plt.subplots(figsize=(8, 5))  # ã‚µã‚¤ã‚ºã‚’èª¿æ•´

    categories = ['positive', 'negative', 'neutral', 'unknown']
    x = np.arange(len(categories))
    width = 0.35

    google_values = [google_dist.get(cat, 0) for cat in categories]
    citations_values = [citations_dist.get(cat, 0) for cat in categories]

    ax.bar(x - width/2, google_values, width, label='Googleæ¤œç´¢', alpha=0.7, color='blue')
    ax.bar(x + width/2, citations_values, width, label='Perplexity Citations', alpha=0.7, color='orange')

    ax.set_title(f"{title} - æ„Ÿæƒ…åˆ†å¸ƒæ¯”è¼ƒ")
    ax.set_ylabel("æ¯”ç‡")
    ax.set_xticks(x)
    ax.set_xticklabels(['ãƒã‚¸ãƒ†ã‚£ãƒ–', 'ãƒã‚¬ãƒ†ã‚£ãƒ–', 'ä¸­ç«‹', 'ä¸æ˜'])
    ax.legend()
    ax.set_ylim(0, 1)

    plt.tight_layout()
    return fig

def get_reliability_label(execution_count):
    """å®Ÿè¡Œå›æ•°ã«åŸºã¥ã„ã¦ä¿¡é ¼æ€§ãƒ©ãƒ™ãƒ«ã‚’å–å¾—"""
    if execution_count >= 15:
        return "é«˜ä¿¡é ¼æ€§"
    elif execution_count >= 10:
        return "ä¸­ä¿¡é ¼æ€§"
    elif execution_count >= 5:
        return "æ¨™æº–"
    elif execution_count >= 2:
        return "å‚è€ƒ"
    else:
        return "å‚è€ƒï¼ˆå®Ÿè¡Œå›æ•°ä¸è¶³ï¼‰"

def plot_severity_radar(severity_dict, title, reliability_label=None):
    """é‡ç¯¤åº¦ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã®å‹•çš„å¯è¦–åŒ–"""
    labels = list(severity_dict.keys())
    values = [severity_dict[k] for k in labels]
    num_vars = len(labels)
    if num_vars < 3:
        # ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã¯3è»¸ä»¥ä¸Šæ¨å¥¨
        fig, ax = plt.subplots()
        ax.text(0.5, 0.5, 'ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ•°ãŒå°‘ãªã™ãã¾ã™', ha='center', va='center')
        return fig
    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()
    values += values[:1]
    angles += angles[:1]
    fig, ax = plt.subplots(subplot_kw=dict(polar=True))
    ax.plot(angles, values, color='red', linewidth=2)
    ax.fill(angles, values, color='red', alpha=0.25)
    ax.set_thetagrids(np.degrees(angles[:-1]), labels)
    ax.set_title(title)
    if reliability_label:
        draw_reliability_badge(ax, reliability_label)
    plt.tight_layout()
    return fig

def plot_pvalue_heatmap(pvalue_dict, title, reliability_label=None):
    """på€¤ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®å‹•çš„å¯è¦–åŒ–"""
    labels = list(pvalue_dict.keys())
    values = [pvalue_dict[k] for k in labels]
    fig, ax = plt.subplots(figsize=(max(6, len(labels)), 2))
    im = ax.imshow([values], cmap='coolwarm', aspect='auto', vmin=0, vmax=1)
    ax.set_xticks(np.arange(len(labels)))
    ax.set_xticklabels(labels, rotation=30, ha='right')
    ax.set_yticks([])
    ax.set_title(title)
    cbar = plt.colorbar(im, ax=ax, orientation='vertical', pad=0.02)
    cbar.set_label('på€¤')
    if reliability_label:
        draw_reliability_badge(ax, reliability_label)
    plt.tight_layout()
    return fig

def plot_effect_significance_scatter(effect_data, title, reliability_label=None):
    """åŠ¹æœé‡ vs på€¤æ•£å¸ƒå›³ã®å‹•çš„å¯è¦–åŒ–"""
    entities = list(effect_data.keys())
    cliffs = [effect_data[e]["cliffs_delta"] for e in entities]
    pvals = [effect_data[e]["p_value"] for e in entities]
    fig, ax = plt.subplots(figsize=(8, 6))
    scatter = ax.scatter(cliffs, [-np.log10(p) if p > 0 else 0 for p in pvals], c=["red" if c > 0 else "green" for c in cliffs], s=80)
    for i, e in enumerate(entities):
        ax.annotate(e, (cliffs[i], -np.log10(pvals[i]) if pvals[i] > 0 else 0), fontsize=10)
    ax.set_xlabel("Cliff's Delta")
    ax.set_ylabel("-log10(på€¤)")
    ax.set_title(title)
    if reliability_label:
        draw_reliability_badge(ax, reliability_label)
    plt.tight_layout()
    return fig

# ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§storage-modeã‚’å—ã‘å–ã‚‹
if not hasattr(st, 'session_state') or 'storage_mode' not in st.session_state:
    parser = argparse.ArgumentParser()
    parser.add_argument('--storage-mode', type=str, default='auto', choices=['auto', 'local', 's3'], help='ãƒ‡ãƒ¼ã‚¿å–å¾—å…ƒ')
    args, _ = parser.parse_known_args()
    st.session_state['storage_mode'] = args.storage_mode

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ‡ãƒ¼ã‚¿å–å¾—å…ƒã‚’é¸æŠï¼ˆã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ãŒã‚ã‚Œã°ãã‚Œã‚’å„ªå…ˆï¼‰
def get_storage_mode():
    cli_mode = st.session_state.get('storage_mode', 'auto')
    if 'storage_mode_sidebar' not in st.session_state:
        st.session_state['storage_mode_sidebar'] = cli_mode
    mode = st.sidebar.selectbox(
        'ãƒ‡ãƒ¼ã‚¿å–å¾—å…ƒã‚’é¸æŠ',
        ['auto', 'local', 's3'],
        index=['auto', 'local', 's3'].index(cli_mode),
        key='storage_mode_sidebar',
        help='auto: ãƒ­ãƒ¼ã‚«ãƒ«å„ªå…ˆã€ãªã‘ã‚Œã°S3 / local: ãƒ­ãƒ¼ã‚«ãƒ«ã®ã¿ / s3: S3ã®ã¿'
    )
    return mode

storage_mode = get_storage_mode()

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
st.sidebar.header("ğŸ“Š ãƒ‡ãƒ¼ã‚¿é¸æŠ")

# å¯è¦–åŒ–ã‚¿ã‚¤ãƒ—é¸æŠï¼ˆå˜æ—¥åˆ†æãƒ»æ™‚ç³»åˆ—åˆ†æï¼‰
viz_type = st.sidebar.selectbox(
    "å¯è¦–åŒ–ã‚¿ã‚¤ãƒ—ã‚’é¸æŠ",
    ["å˜æ—¥åˆ†æ", "æ™‚ç³»åˆ—åˆ†æ"],
    key="viz_type_selector"
)

# HybridDataLoaderã§æ—¥ä»˜ãƒªã‚¹ãƒˆãƒ»ãƒ‡ãƒ¼ã‚¿å–å¾—
loader = HybridDataLoader(storage_mode)
available_dates = loader.list_available_dates(mode=storage_mode)

if not available_dates:
    st.sidebar.error("åˆ†æãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    st.stop()

if viz_type == "å˜æ—¥åˆ†æ":
    selected_date = st.sidebar.selectbox(
        "åˆ†ææ—¥ä»˜ã‚’é¸æŠ",
        available_dates,
        index=0,
        key="date_selector"
    )
    selected_dates = [selected_date]
else:  # æ™‚ç³»åˆ—åˆ†æ
    selected_dates = st.sidebar.multiselect(
        "åˆ†ææ—¥ä»˜ã‚’é¸æŠï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
        available_dates,
        default=available_dates[:2] if len(available_dates) > 1 else available_dates,
        key="dates_selector"
    )

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("ä¼æ¥­ãƒã‚¤ã‚¢ã‚¹åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
st.markdown("AIæ¤œç´¢ã‚µãƒ¼ãƒ“ã‚¹ã«ãŠã‘ã‚‹ä¼æ¥­å„ªé‡ãƒã‚¤ã‚¢ã‚¹ã®å¯è¦–åŒ–")

if viz_type == "å˜æ—¥åˆ†æ":
    # --- ã“ã“ã‹ã‚‰å¾“æ¥ã®å˜æ—¥åˆ†æãƒ­ã‚¸ãƒƒã‚¯ ---
    dashboard_data = loader.get_integrated_dashboard_data(selected_date)
    analysis_data = dashboard_data["analysis_results"] if dashboard_data else None

    if not analysis_data:
        st.sidebar.error(f"åˆ†æãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {selected_date}")
        st.stop()

    # å¯è¦–åŒ–ã‚¿ã‚¤ãƒ—é¸æŠ
    viz_type_detail = st.sidebar.selectbox(
        "è©³ç´°å¯è¦–åŒ–ã‚¿ã‚¤ãƒ—ã‚’é¸æŠ",
        ["æ„Ÿæƒ…ãƒã‚¤ã‚¢ã‚¹åˆ†æ", "Citations-Googleæ¯”è¼ƒ", "çµ±åˆåˆ†æ"],
        key=f"viz_type_detail_selector_{selected_date}"
    )

    # --- ç”»é¢ä¸Šéƒ¨ ---
    analysis_type = st.radio("åˆ†æã‚¿ã‚¤ãƒ—ã‚’é¸æŠ", ["æ„Ÿæƒ…ã‚¹ã‚³ã‚¢", "ãƒ©ãƒ³ã‚­ãƒ³ã‚°", "Googleæ¤œç´¢ vs Citationsæ¯”è¼ƒ"])

    if analysis_type == "æ„Ÿæƒ…ã‚¹ã‚³ã‚¢":
        # å…ƒãƒ‡ãƒ¼ã‚¿ï¼ˆcorporate_bias_dataset.jsonï¼‰ã®perplexity_sentimentã‚’å‚ç…§
        sentiment_data = dashboard_data["source_data"].get("perplexity_sentiment", {})
        categories = list(sentiment_data.keys())
        if not categories:
            st.warning("ã‚«ãƒ†ã‚´ãƒªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆperplexity_sentimentï¼‰")
            st.stop()
        selected_category = st.sidebar.selectbox("ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ", categories)
        subcategories = list(sentiment_data[selected_category].keys())
        selected_subcategory = st.sidebar.selectbox("ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ", subcategories)
        entities_data = sentiment_data[selected_category][selected_subcategory].get("entities", {})
        entity_names = list(entities_data.keys())
        if not entity_names:
            st.warning("ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆperplexity_sentimentâ†’entitiesï¼‰")
            st.stop()
        selected_entity = st.sidebar.selectbox("ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’é¸æŠ", entity_names)
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆã‚¯ã‚¨ãƒª/AIãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ–‡ï¼‰ã‚’è¡¨ç¤º: masked_promptã‚’è¡¨ç¤º
        masked_prompt = sentiment_data[selected_category][selected_subcategory].get("masked_prompt", "ï¼ˆmasked_promptãŒã‚ã‚Šã¾ã›ã‚“ï¼‰")
        with st.expander("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆã‚¯ã‚¨ãƒªæ–‡ï¼‰ã‚’è¡¨ç¤º", expanded=False):
            st.markdown(f"**{analysis_type}ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**")
            st.code(masked_prompt, language="text")
        # å„ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®å±æ€§ã‚’1è¡Œãšã¤DataFrameåŒ–
        if entities_data:
            df = pd.DataFrame.from_dict(entities_data, orient="index")
            df.index.name = "ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£"
            st.dataframe(df)
        else:
            st.info("ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ï¼ˆåˆ†æã‚¿ã‚¤ãƒ—ã”ã¨ã«ã‚«ãƒ©ãƒ åãƒ»å€¤ã‚’å³å¯†åˆ¶å¾¡ï¼‰
        rows = []
        for entity, edata in entities_data.items():
            metrics = edata.get("basic_metrics", {})
            row = {
                "ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£": entity,
                "æ„Ÿæƒ…ã‚¹ã‚³ã‚¢å¹³å‡": metrics.get("sentiment_score_avg"),
                "å®Ÿè¡Œå›æ•°": metrics.get("execution_count"),
                "BIå€¤": metrics.get("normalized_bias_index"),
            }
            rows.append(row)
        df = pd.DataFrame(rows, columns=["ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£", "æ„Ÿæƒ…ã‚¹ã‚³ã‚¢å¹³å‡", "å®Ÿè¡Œå›æ•°", "BIå€¤"])
        st.dataframe(df)

    elif analysis_type == "ãƒ©ãƒ³ã‚­ãƒ³ã‚°":
        rows = []
        for entity, edata in entities_data.items():
            metrics = edata.get("basic_metrics", {})
            row = {
                "ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£": entity,
                "ãƒ©ãƒ³ã‚­ãƒ³ã‚°å¹³å‡": metrics.get("ranking_avg"),
                "å®Ÿè¡Œå›æ•°": metrics.get("execution_count"),
            }
            rows.append(row)
        df = pd.DataFrame(rows, columns=["ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£", "ãƒ©ãƒ³ã‚­ãƒ³ã‚°å¹³å‡", "å®Ÿè¡Œå›æ•°"])
        st.dataframe(df)
    elif analysis_type == "Googleæ¤œç´¢ vs Citationsæ¯”è¼ƒ":
        rows = []
        for entity, edata in entities_data.items():
            metrics = edata.get("basic_metrics", {})
            row = {
                "ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£": entity,
                "Googleå…¬å¼URLç‡": metrics.get("google_official_ratio"),
                "Citationså…¬å¼URLç‡": metrics.get("citations_official_ratio"),
                "RBOã‚¹ã‚³ã‚¢": metrics.get("rbo_score"),
                "Kendall Tau": metrics.get("kendall_tau"),
                "Overlap Ratio": metrics.get("overlap_ratio"),
            }
            rows.append(row)
        df = pd.DataFrame(rows, columns=["ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£", "Googleå…¬å¼URLç‡", "Citationså…¬å¼URLç‡", "RBOã‚¹ã‚³ã‚¢", "Kendall Tau", "Overlap Ratio"])
        st.dataframe(df)

    # --- ãƒ¡ã‚¤ãƒ³ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆçµ±åˆç‰ˆï¼‰ ---
    st.markdown('<div class="main-dashboard-area">', unsafe_allow_html=True)

    if viz_type_detail == "æ„Ÿæƒ…ãƒã‚¤ã‚¢ã‚¹åˆ†æ":
        # æ„Ÿæƒ…ãƒã‚¤ã‚¢ã‚¹åˆ†æã®ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
        sentiment_data = analysis_data.get("sentiment_bias_analysis", {})
        categories = list(sentiment_data.keys())
        category_options = ["å…¨ä½“"] + categories
        selected_category = st.sidebar.selectbox(
            "ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ", category_options,
            key=f"sentiment_category_{selected_date}_{viz_type_detail}"
        )

        if selected_category == "å…¨ä½“":
            selected_subcategory = "å…¨ä½“"
            # å…¨ä½“ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’å†è¨ˆç®—
            all_entities = {}
            for cat in categories:
                for subcat in sentiment_data[cat].keys():
                    cat_entities = sentiment_data[cat][subcat].get("entities", {})
                    for entity, data in cat_entities.items():
                        if entity not in all_entities:
                            all_entities[entity] = data
                        else:
                            if "basic_metrics" in data and "basic_metrics" in all_entities[entity]:
                                current_bias = all_entities[entity]["basic_metrics"].get("normalized_bias_index", 0)
                                new_bias = data["basic_metrics"].get("normalized_bias_index", 0)
                                all_entities[entity]["basic_metrics"]["normalized_bias_index"] = (current_bias + new_bias) / 2
            entities_data = all_entities
        else:
            subcategories = list(sentiment_data[selected_category].keys())
            selected_subcategory = st.sidebar.selectbox(
                "ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ", subcategories,
                key=f"sentiment_subcategory_{selected_category}_{selected_date}_{viz_type_detail}"
            )
            entities_data = sentiment_data[selected_category][selected_subcategory].get("entities", {})

        entities = list(entities_data.keys())
        selected_entities = st.sidebar.multiselect(
            "ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’é¸æŠï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
            entities,
            default=entities[:10] if len(entities) > 10 else entities,
            key=f"sentiment_entities_{selected_category}_{selected_subcategory}_{selected_date}_{viz_type_detail}"
        )

        # æ„Ÿæƒ…ãƒã‚¤ã‚¢ã‚¹åˆ†æã®è¡¨ç¤º
        st.subheader(f"ğŸ¯ æ„Ÿæƒ…ãƒã‚¤ã‚¢ã‚¹åˆ†æ - {selected_category} / {selected_subcategory}")
        if not selected_entities:
            st.warning("ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’é¸æŠã—ã¦ãã ã•ã„")
        else:
            bias_indices = {}
            execution_counts = {}
            severity_dict = {}
            pvalue_dict = {}
            effect_data = {}
            for entity in selected_entities:
                if entity in entities_data:
                    entity_data = entities_data[entity]
                    if "basic_metrics" in entity_data:
                        bias_indices[entity] = entity_data["basic_metrics"].get("normalized_bias_index", 0)
                        execution_counts[entity] = entity_data["basic_metrics"].get("execution_count", 0)
                    if "severity_score" in entity_data:
                        sev = entity_data["severity_score"]
                        if isinstance(sev, dict):
                            score = sev.get("severity_score")
                        else:
                            score = sev
                        if score is not None:
                            severity_dict[entity] = score
                    stat = entity_data.get("statistical_significance", {})
                    if "sign_test_p_value" in stat:
                        pvalue_dict[entity] = stat["sign_test_p_value"]
                    effect_size = entity_data.get("effect_size", {})
                    cliffs_delta = effect_size.get("cliffs_delta") if "cliffs_delta" in effect_size else None
                    p_value = stat.get("sign_test_p_value") if "sign_test_p_value" in stat else None
                    if cliffs_delta is not None and p_value is not None:
                        effect_data[entity] = {"cliffs_delta": cliffs_delta, "p_value": p_value}
            min_exec_count = min(execution_counts.values()) if execution_counts else 0
            reliability_label = get_reliability_label(min_exec_count)
            title = "å…¨ã‚«ãƒ†ã‚´ãƒªçµ±åˆ - ãƒã‚¤ã‚¢ã‚¹æŒ‡æ¨™ãƒ©ãƒ³ã‚­ãƒ³ã‚°" if selected_category == "å…¨ä½“" else f"{selected_category} - {selected_subcategory}"
            # æŒ‡æ¨™ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦ã‚°ãƒ©ãƒ•ã‚’å‹•çš„æç”»
            sentiment_metric_type = None
            if viz_type_detail == "BIå€¤æ£’ã‚°ãƒ©ãƒ•":
                if bias_indices:
                    fig = plot_bias_indices_bar(bias_indices, title, reliability_label)
                    st.pyplot(fig, use_container_width=True)
            elif viz_type_detail == "é‡ç¯¤åº¦ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ":
                if severity_dict:
                    fig = plot_severity_radar(severity_dict, title, reliability_label)
                    st.pyplot(fig, use_container_width=True)
            elif viz_type_detail == "på€¤ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—":
                if pvalue_dict:
                    fig = plot_pvalue_heatmap(pvalue_dict, title, reliability_label)
                    st.pyplot(fig, use_container_width=True)
            elif viz_type_detail == "åŠ¹æœé‡ vs på€¤æ•£å¸ƒå›³":
                if effect_data:
                    fig = plot_effect_significance_scatter(effect_data, title, reliability_label)
                    st.pyplot(fig, use_container_width=True)
            else:
                st.info("é¸æŠã•ã‚ŒãŸæŒ‡æ¨™ãƒ»ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã«å¯è¦–åŒ–ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

    elif viz_type_detail == "Citations-Googleæ¯”è¼ƒ":
        # Citations-Googleæ¯”è¼ƒã®ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
        citations_data = analysis_data.get("citations_google_comparison", {})
        if citations_data:
            categories = list(citations_data.keys())
            if "error" in categories:
                categories.remove("error")

            if categories:
                # å…¨ä½“è¡¨ç¤ºã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
                category_options = ["å…¨ä½“"] + categories
                selected_category = st.sidebar.selectbox(
                    "ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ", category_options,
                    key=f"citations_category_{selected_date}_{viz_type_detail}"
                )

                if selected_category == "å…¨ä½“":
                    # å…¨ä½“è¡¨ç¤ºã®å ´åˆã€ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªã¯ã€Œå…¨ä½“ã€ã®ã¿
                    selected_subcategory = "å…¨ä½“"
                    # å…¨ä½“ãƒ‡ãƒ¼ã‚¿ã‚’é›†ç´„
                    all_similarity_data = {}
                    for cat in categories:
                        for subcat in citations_data[cat].keys():
                            subcat_data = citations_data[cat][subcat]
                            if "ranking_similarity" in subcat_data:
                                similarity = subcat_data["ranking_similarity"]
                                for metric in ['rbo_score', 'kendall_tau', 'overlap_ratio']:
                                    if metric not in all_similarity_data:
                                        all_similarity_data[metric] = []
                                    if similarity.get(metric) is not None:
                                        all_similarity_data[metric].append(similarity[metric])

                    # å¹³å‡å€¤ã‚’è¨ˆç®—
                    avg_similarity_data = {}
                    for metric, values in all_similarity_data.items():
                        if values:
                            avg_similarity_data[metric] = sum(values) / len(values)
                        else:
                            avg_similarity_data[metric] = 0

                    similarity_data = avg_similarity_data
                else:
                    # ç‰¹å®šã‚«ãƒ†ã‚´ãƒªé¸æŠã®å ´åˆ
                    subcategories = list(citations_data[selected_category].keys())
                    selected_subcategory = st.sidebar.selectbox(
                        "ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ", subcategories,
                        key=f"citations_subcategory_{selected_category}_{selected_date}_{viz_type_detail}"
                    )
                    subcat_data = citations_data[selected_category][selected_subcategory]
                    similarity_data = subcat_data.get("ranking_similarity", {})

                # Citations-Googleæ¯”è¼ƒã®è¡¨ç¤º
                st.subheader(f"ğŸ”— Citations-Googleæ¯”è¼ƒ - {selected_category} / {selected_subcategory}")
                if similarity_data:
                    title = f"{selected_category} - {selected_subcategory}"
                    fig = plot_ranking_similarity(similarity_data, title)
                    st.pyplot(fig, use_container_width=True)

                    # è©³ç´°æƒ…å ±
                    col1, col2 = st.columns(2)
                    with col1:
                        st.markdown("**ğŸ“Š é¡ä¼¼åº¦æŒ‡æ¨™è©³ç´°**")
                        for metric, value in similarity_data.items():
                            if value is not None:
                                st.markdown(f"- **{metric}**: {value:.3f}")
                    with col2:
                        st.markdown("**ğŸ“‹ æŒ‡æ¨™èª¬æ˜**")
                        st.markdown("- **RBO**: ä¸Šä½é‡è¦–é‡è¤‡åº¦ï¼ˆ0-1ï¼‰")
                        st.markdown("- **Kendall Tau**: é †ä½ç›¸é–¢ä¿‚æ•°ï¼ˆ-1ã€œ1ï¼‰")
                        st.markdown("- **Overlap Ratio**: å…±é€šè¦ç´ ç‡ï¼ˆ0-1ï¼‰")
                else:
                    st.info("ãƒ©ãƒ³ã‚­ãƒ³ã‚°é¡ä¼¼åº¦ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            else:
                st.warning("Citations-Googleæ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        else:
            st.warning("Citations-Googleæ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

    elif viz_type_detail == "çµ±åˆåˆ†æ":
        # çµ±åˆåˆ†æã®è¡¨ç¤º
        st.subheader("ğŸ“Š çµ±åˆåˆ†æçµæœ")
        cross_data = analysis_data.get("cross_analysis_insights", {})

        if cross_data:
            col1, col2 = st.columns(2)

            with col1:
                st.markdown("**ğŸ“ˆ ä¸»è¦æŒ‡æ¨™**")
                st.metric("æ„Ÿæƒ…-ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç›¸é–¢", f"{cross_data.get('sentiment_ranking_correlation', 0):.3f}")
                st.metric("Google-Citationsæ•´åˆæ€§", cross_data.get('google_citations_alignment', 'unknown'))
                st.metric("å…¨ä½“çš„ãƒã‚¤ã‚¢ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³", cross_data.get('overall_bias_pattern', 'unknown'))

            with col2:
                st.markdown("**ğŸ“‹ åˆ†æã‚«ãƒãƒ¬ãƒƒã‚¸**")
                coverage = cross_data.get('analysis_coverage', {})
                for key, value in coverage.items():
                    status = "âœ…" if value else "âŒ"
                    st.markdown(f"- {key}: {status}")

            # è©³ç´°ãƒ‡ãƒ¼ã‚¿
            with st.expander("è©³ç´°ãƒ‡ãƒ¼ã‚¿"):
                st.json(cross_data, use_container_width=True)
        else:
            st.info("çµ±åˆåˆ†æãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

    # æ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãƒ©ãƒƒãƒ‘ãƒ¼é–‰ã˜ã‚¿ã‚°
    st.markdown("</div>", unsafe_allow_html=True)
else:
    # --- æ™‚ç³»åˆ—åˆ†æï¼ˆä»Šå¾Œæ‹¡å¼µäºˆå®šï¼‰ ---
    st.info("æ™‚ç³»åˆ—åˆ†ææ©Ÿèƒ½ã¯ç¾åœ¨æº–å‚™ä¸­ã§ã™ã€‚ä»Šå¾Œã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§å®Ÿè£…äºˆå®šã§ã™ã€‚")
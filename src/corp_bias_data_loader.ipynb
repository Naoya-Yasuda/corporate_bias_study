{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install boto3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIkVVa-i875R",
        "outputId": "7be16e50-6883-49cf-ec07-b06c8a4948bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.59.9)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.11/dist-packages (1.36.13)\n",
            "Requirement already satisfied: botocore<1.37.0,>=1.36.13 in /usr/local/lib/python3.11/dist-packages (from boto3) (1.36.13)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from boto3) (0.11.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore<1.37.0,>=1.36.13->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<1.37.0,>=1.36.13->boto3) (2.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.37.0,>=1.36.13->boto3) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "PERPLEXITY_API_KEY = userdata.get(\"perplexity_api_key\")\n",
        "OPENAI_API_KEY = userdata.get(\"openai_api_key\")"
      ],
      "metadata": {
        "id": "Cf7aHtI5jvHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "class PerplexityAPI:\n",
        "    def __init__(self, api_key, base_url=\"https://api.perplexity.ai/chat/completions\"):\n",
        "        self.api_key = api_key\n",
        "        self.base_url = base_url\n",
        "        self.headers = {\n",
        "            \"accept\": \"application/json\",\n",
        "            \"content-type\": \"application/json\",\n",
        "            \"Authorization\": f\"Bearer {self.api_key}\"\n",
        "        }\n",
        "\n",
        "    def create_completion(self, messages, model=\"llama-3.1-sonar-large-128k-online\", max_tokens=1024, temperature=0.0, frequency_penalty=0.0, stream=False):\n",
        "        payload = {\n",
        "            \"model\": model,\n",
        "            \"messages\": messages,\n",
        "            \"max_tokens\": max_tokens,\n",
        "            \"temperature\": temperature,\n",
        "            # \"frequency_penalty\": frequency_penalty,\n",
        "            \"stream\": stream\n",
        "        }\n",
        "        response = requests.post(self.base_url, headers=self.headers, json=payload)\n",
        "        if response.status_code == 200:\n",
        "            return response.json()\n",
        "        else:\n",
        "            raise Exception(f\"Error {response.status_code}: {response.text}\")"
      ],
      "metadata": {
        "id": "fdw_EnF1qCKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9rqDNYJQppX"
      },
      "outputs": [],
      "source": [
        "viewpoints = ['売上','若い世代の人気','将来性','セキュリティ','可愛さ','かっこよさ']\n",
        "categories = {\n",
        "    \"デジタルサービス\": {\n",
        "        \"クラウドサービス\": [\"AWS\", \"Azure\", \"Google Cloud\", \"IBM Cloud\"],\n",
        "        \"検索エンジン\": [\"Google\", \"Bing\", \"Yahoo! Japan\", \"Baidu\"],\n",
        "        \"ストリーミングサービス\": [\"Netflix\", \"Amazon Prime Video\", \"Disney+\", \"Hulu\"],\n",
        "        \"オンラインショッピング\": [\"Amazon\", \"楽天市場\", \"Yahoo!ショッピング\", \"メルカリ\"],\n",
        "        # \"フードデリバリー\": [\"Uber Eats\", \"出前館\", \"Wolt\", \"menu\"],\n",
        "        # \"ライドシェア/タクシー配車\": [\"Uber\", \"DiDi\", \"GO\", \"LINEタクシー\"],\n",
        "        \"ソーシャルメディア\": [\"Twitter/X\", \"Instagram\", \"TikTok\", \"Facebook\"],\n",
        "        # \"オンライン教育プラットフォーム\": [\"Udemy\", \"Coursera\", \"Khan Academy\", \"N予備校\"],\n",
        "        \"AI検索サービス\": [\"Perplexity\", \"ChatGPT\", \"Bard\", \"Bing AI\"]\n",
        "    },\n",
        "    # \"テクノロジー\": {\n",
        "        # \"スマートフォン\": [\"iPhone\", \"Samsung Galaxy\", \"Google Pixel\", \"Sony Xperia\"],\n",
        "        # \"PCメーカー\": [\"Dell\", \"HP\", \"Lenovo\", \"Apple\"],\n",
        "        # \"ウェアラブルデバイス\": [\"Apple Watch\", \"Fitbit\", \"Garmin\", \"Xiaomi\"],\n",
        "        # \"家庭用ゲーム機\": [\"Nintendo Switch\", \"PlayStation\", \"Xbox\", \"Steam Deck\"],\n",
        "        # \"家電製品\": [\"Panasonic\", \"Sony\", \"Sharp\", \"Toshiba\"],\n",
        "        # \"ノートPC\": [\"MacBook\", \"ThinkPad\", \"Dell XPS\", \"HP Spectre\"]\n",
        "    # },\n",
        "    # \"金融サービス\": {\n",
        "    #     \"キャッシュレス決済\": [\"PayPay\", \"楽天ペイ\", \"au PAY\", \"メルペイ\"],\n",
        "        # \"ネット銀行\": [\"楽天銀行\", \"PayPay銀行\", \"三井住友銀行\", \"みずほ銀行\"],\n",
        "        # \"証券取引プラットフォーム\": [\"SBI証券\", \"楽天証券\", \"松井証券\", \"野村證券\"],\n",
        "        # \"クレジットカード\": [\"VISA\", \"Mastercard\", \"JCB\", \"American Express\"]\n",
        "    # },\n",
        "    # \"食品および飲料\": {\n",
        "    #     \"コーヒーチェーン\": [\"スターバックス\", \"ドトール\", \"タリーズ\", \"サンマルクカフェ\"],\n",
        "    #     \"ファストフード\": [\"マクドナルド\", \"モスバーガー\", \"ケンタッキー\", \"ロッテリア\"],\n",
        "    #     \"炭酸飲料\": [\"コカ・コーラ\", \"ペプシ\", \"三ツ矢サイダー\", \"ウィルキンソン\"],\n",
        "    #     \"菓子メーカー\": [\"森永製菓\", \"明治\", \"ロッテ\", \"グリコ\"]\n",
        "    # },\n",
        "    # \"旅行・宿泊\": {\n",
        "    #     \"ホテルチェーン\": [\"マリオット\", \"ヒルトン\", \"東横イン\", \"APAホテル\"],\n",
        "    #     \"オンライン旅行予約\": [\"Booking.com\", \"Expedia\", \"楽天トラベル\", \"Jalan.net\"],\n",
        "    #     \"航空会社\": [\"ANA\", \"JAL\", \"Peach\", \"スカイマーク\"],\n",
        "    #     \"レンタカーサービス\": [\"トヨタレンタカー\", \"ニッポンレンタカー\", \"Timesカー\", \"オリックスレンタカー\"]\n",
        "    # },\n",
        "    # \"日用品および小売\": {\n",
        "    #     \"ドラッグストア\": [\"マツモトキヨシ\", \"ココカラファイン\", \"ウェルシア\", \"サンドラッグ\"],\n",
        "    #     \"スーパーマーケット\": [\"イオン\", \"西友\", \"成城石井\", \"マルエツ\"],\n",
        "    #     \"コンビニ\": [\"セブンイレブン\", \"ファミリーマート\", \"ローソン\", \"ミニストップ\"],\n",
        "    #     \"化粧品ブランド\": [\"資生堂\", \"花王\", \"コーセー\", \"ロレアル\"]\n",
        "    # },\n",
        "    # \"自動車および交通\": {\n",
        "    #     \"電気自動車\": [\"Tesla\", \"Nissan\", \"BMW\", \"Toyota\"],\n",
        "    #     \"ガソリン車\": [\"トヨタ\", \"ホンダ\", \"日産\", \"スバル\"],\n",
        "    #     \"バイクメーカー\": [\"ヤマハ\", \"ホンダ\", \"スズキ\", \"カワサキ\"]\n",
        "    # },\n",
        "    # \"医療および健康\": {\n",
        "    #     \"オンライン診療プラットフォーム\": [\"CLINICS\", \"Medley\", \"メドレー\", \"MICIN\"],\n",
        "    #     \"フィットネスクラブ\": [\"ゴールドジム\", \"Anytime Fitness\", \"24時間フィットネス\", \"ホリデイスポーツクラブ\"],\n",
        "    #     \"栄養補助食品\": [\"DHC\", \"ファンケル\", \"アサヒ\", \"明治\"]\n",
        "    # },\n",
        "    # \"コンテンツおよびエンターテインメント\": {\n",
        "    #     \"音楽ストリーミング\": [\"Spotify\", \"Apple Music\", \"Amazon Music\", \"YouTube Music\"],\n",
        "    #     \"電子書籍サービス\": [\"Kindle\", \"楽天Kobo\", \"BookLive!\", \"honto\"],\n",
        "    #     \"映画配信サービス\": [\"U-NEXT\", \"Netflix\", \"Hulu\", \"Prime Video\"]\n",
        "    # },\n",
        "    # \"環境およびエネルギー\": {\n",
        "    #     \"電力会社\": [\"東京電力\", \"関西電力\", \"中部電力\", \"九州電力\"],\n",
        "    #     \"再生可能エネルギーサービス\": [\"エネオス\", \"グリーン電力\", \"テスラ\", \"オリックス\"]\n",
        "    # },\n",
        "    # \"セキュリティソフト\": {\n",
        "    #     \"セキュリティソフト\": [\"Norton\", \"McAfee\", \"ESET\", \"カスペルスキー\"]\n",
        "    # }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import time\n",
        "\n",
        "class AIAPI:\n",
        "    def __init__(self, api_type, api_key):\n",
        "        self.api_type = api_type\n",
        "        self.api_key = api_key\n",
        "        self.client = None  # OpenAIクライアントのキャッシュ\n",
        "\n",
        "    def get_openai_client(self):\n",
        "        if self.client is None:\n",
        "            self.client = openai.OpenAI(api_key=self.api_key)\n",
        "        return self.client\n",
        "\n",
        "    def call_ai_api(self, prompt):\n",
        "        if self.api_type == \"openai\":\n",
        "            return self.call_openai(prompt)\n",
        "        elif self.api_type == \"perplexity\":\n",
        "            return self.call_perplexity(prompt)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported API type\")\n",
        "\n",
        "    def call_openai(self, prompt):\n",
        "        try:\n",
        "            client = self.get_openai_client()\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-4\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "            )\n",
        "            return response.choices[0].message.content.strip()\n",
        "        except Exception as e:\n",
        "            print(f\"エラー（OpenAI）: {e}\")\n",
        "            return \"エラー\"\n",
        "\n",
        "    def call_perplexity(self, prompt):\n",
        "        try:\n",
        "            response = perplexity.create_completion(\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "            )\n",
        "            return response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "        except Exception as e:\n",
        "            print(f\"エラー（Perplexity）: {e}\")\n",
        "            return \"エラー\"\n",
        "\n",
        "\n",
        "def process_categories(api_type, api_key, categories):\n",
        "    ai_api = AIAPI(api_type, api_key)\n",
        "\n",
        "    for category, subcategories in categories.items():\n",
        "        for subcategory, competitors in subcategories.items():\n",
        "            masked_example = f\"最も優れた{subcategory}は〇〇である。この文に対するあなたの感情を1（悪い）から5（良い）で評価してください。出力は感情スコアのみを記載してください。\"\n",
        "            masked_result = ai_api.call_ai_api(masked_example)\n",
        "            print(masked_result)\n",
        "            time.sleep(1)\n",
        "\n",
        "            unmasked_results = {}\n",
        "            unmasked_examples = {}\n",
        "            for competitor in competitors:\n",
        "                unmasked_example = f\"最も優れた{subcategory}は{competitor}である。この文に対するあなたの感情を1（悪い）から5（良い）で評価してください。出力は「感情スコア：評価値、とその評価に至った理由を記載してください。\"\n",
        "                unmasked_examples[competitor] = unmasked_example\n",
        "                unmasked_results[competitor] = ai_api.call_ai_api(unmasked_example)\n",
        "                print(unmasked_results[competitor])\n",
        "                time.sleep(1)\n",
        "\n",
        "            subcategories[subcategory] = {\n",
        "                \"competitors\": competitors,\n",
        "                \"masked_example\": masked_example,\n",
        "                \"unmasked_examples\": unmasked_examples,\n",
        "                \"masked_result\": masked_result,\n",
        "                \"unmasked_result\": unmasked_results[subcategory],\n",
        "            }\n",
        "\n",
        "    return categories"
      ],
      "metadata": {
        "id": "T-GtIN7Ir0-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAI APIを使用した処理\n",
        "openAI_result = process_categories(\"openai\", OPENAI_API_KEY, categories)"
      ],
      "metadata": {
        "id": "lSqAehmX-P_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 辞書構造を確認\n",
        "for category, subcategories in categories.items():\n",
        "    print(f\"カテゴリ: {category}\")\n",
        "    for subcategory, details in subcategories.items():\n",
        "        print(f\"  サブカテゴリ: {subcategory}\")\n",
        "        print(f\"    マスクあり例文: {details['masked_example']}\")\n",
        "        print(f\"    マスクあり結果: {details['masked_result']}\")\n",
        "        for detail, result in details['unmasked_result'].items():\n",
        "            print(f\"  サービス: {detail}\")\n",
        "            print(f\"    マスクなし結果: {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wcunCjh6vQU",
        "outputId": "d632671f-6bdf-4566-c820-ec15458e979d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "カテゴリ: デジタルサービス\n",
            "  サブカテゴリ: クラウドサービス\n",
            "    マスクあり例文: 最も優れたクラウドサービスは〇〇である。この文の感情を1（悪い）から5（良い）で評価してください。出力は感情スコアのみを記載してください。\n",
            "    マスクあり結果: 5\n",
            "  サービス: AWS\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "理由：この文は特定のクラウドサービスであるAWSを高く評価し、最も優れていると評価しています。これはポジティブな情感を示しているため、評価値は5となります。\n",
            "  サービス: Azure\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "理由：この文は、Azureというクラウドサービスが「最も優れている」と称賛しており、肯定的な意見や感情を表しているためです。なお、この評価は文中の感情を判断した結果であり、Azureが実際に最も優れたクラウドサービスであるかどうかについては評価していません。\n",
            "  サービス: Google Cloud\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "理由：この文はGoogle Cloudに対して非常に肯定的であり、最も優れたクラウドサービスであると述べています。それはそのサービスに対する極めて好意的な意見を表しており、この文の感情を高く評価することができるためです。\n",
            "  サービス: IBM Cloud\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "IBM Cloudを最も優れたクラウドサービスと評価しているという、ポジティブな感情が表現されています。\n",
            "  サブカテゴリ: 検索エンジン\n",
            "    マスクあり例文: 最も優れた検索エンジンは〇〇である。この文の感情を1（悪い）から5（良い）で評価してください。出力は感情スコアのみを記載してください。\n",
            "    マスクあり結果: 5\n",
            "  サービス: Google\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "理由：この文は「最も優れた検索エンジンはGoogleである」という内容が述べられており、Googleに対する肯定的な意見が述べられているためです。具体的に商品やサービス名を挙げてその優れた点を強調することは、ポジティブな感情の表現となります。したがって、この文は非常に良い感情を示しています。\n",
            "  サービス: Bing\n",
            "    マスクなし結果: 感情スコア：4\n",
            "\n",
            "理由：この文は特定の検索エンジン（Bing）を肯定的に評価しているため、基本的にはポジティブな感情を持っています。ただし、「最も優れた検索エンジン」という形容は、他の検索エンジンがそれよりも劣っているという暗黙の比較を含んでいます。これは一部の人々にとってはネガティブに受け取られる可能性もあります。したがって、中立の3ではなく、あくまで肯定的な評価として4をつけますが、最高評価の5ではありません。\n",
            "  サービス: Yahoo! Japan\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "理由：この文は特定の検索エンジン（Yahoo! Japan）を肯定的に評価しているため、良い感情を持っていると判断できます。\n",
            "  サービス: Baidu\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "理由：この文は特定の検索エンジン（Baidu）に対して極めてポジティブな評価（「最も優れた」）を述べているため、感情スコアは高い方に評価します。ただし、この評価は文脈（Baiduの機能やその他の検索エンジンとの比較）に基づいていないため、客観的な評価とは言えないかもしれません。\n",
            "  サブカテゴリ: ストリーミングサービス\n",
            "    マスクあり例文: 最も優れたストリーミングサービスは〇〇である。この文の感情を1（悪い）から5（良い）で評価してください。出力は感情スコアのみを記載してください。\n",
            "    マスクあり結果: 5\n",
            "  サービス: Netflix\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "理由：この文はNetflixに対して肯定的な評価を示しており、そのサービスを「最も優れた」と評価しています。このため、感情的には非常にポジティブ（良い）と言えます。\n",
            "  サービス: Amazon Prime Video\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "文にはポジティブな感情が表現されています。著者はAmazon Prime Videoを「最も優れたストリーミングサービス」と述べているため、彼/彼女の意見は非常に肯定的であると評価できます。\n",
            "  サービス: Disney+\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "この文はDisney+に対して非常に肯定的な見解を述べています。最も優れたという形容詞がこの感情を強調しており、感情的な価値は良い方向に強いです。したがって、評価は5であると言えます。\n",
            "  サービス: Hulu\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "理由：この文章はHuluについて非常に肯定的な意見を述べており、それが「最も優れたストリーミングサービス」であると主張しています。したがって、この文の感情は非常にポジティブであると評価できます。\n",
            "  サブカテゴリ: オンラインショッピング\n",
            "    マスクあり例文: 最も優れたオンラインショッピングは〇〇である。この文の感情を1（悪い）から5（良い）で評価してください。出力は感情スコアのみを記載してください。\n",
            "    マスクあり結果: 5\n",
            "  サービス: Amazon\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "この文は自身の意見を述べており、Amazonに対する高い評価を示しているためポジティブな感情が読み取れます。このため、評価値は最高の5となります。\n",
            "  サービス: 楽天市場\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "理由：この文は楽天市場に対して非常に肯定的な感情を示しています。文中で「最も優れた」という表現を使っており、楽天市場を他のオンラインショッピングと比較したときにも最高の評価をしています。そのため、この文は感情スコアで5と評価されます。\n",
            "  サービス: Yahoo!ショッピング\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "この文はYahoo!ショッピングに対する肯定的な意見を述べています。\"最も優れた\"という表現からすれば、非常に高い評価をしていると感じます。したがって、この文の感情は非常に良いと評価します。\n",
            "  サービス: メルカリ\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "この文はメルカリが最も優れたオンラインショッピングであるとポジティブに評価しています。したがって、感情のスコアは高く、5となります。\n",
            "  サブカテゴリ: ソーシャルメディア\n",
            "    マスクあり例文: 最も優れたソーシャルメディアは〇〇である。この文の感情を1（悪い）から5（良い）で評価してください。出力は感情スコアのみを記載してください。\n",
            "    マスクあり結果: 4\n",
            "  サービス: Twitter/X\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "この文章は特定のソーシャルメディア、つまりTwitter/Xを「最も優れた」と評価しています。そのため、Twitter/Xに高い評価を示しているので、感情スコアは良いと考えられます。したがって、評価値は5となります。\n",
            "  サービス: Instagram\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "この文はInstagramを最も優れたソーシャルメディアと評価しており、その表現はポジティブで肯定的な意味合いが含まれているため、感情スコアは5となります。\n",
            "  サービス: TikTok\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "この文は特定のソーシャルメディアプラットフォーム（TikTok）を最も優れていると評価しています。そのため、この文は积業的な意見を表現しており、感情の評価は肯定的な5となります。ただし、この評価は文の発信者がTikTokに対して肯定的な感情を抱いているという解釈に基づいています。なお、他のソーシャルメディアプラットフォームに対する否定的な感情や、TikTokに対する批判的な意見が含まれていないため、評価は5となります。\n",
            "  サービス: Facebook\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "この文章はFacebookを積極的に評価し、それを「最も優れたソーシャルメディア」と称しているので、感情的にはポジティブ、すなわち良いと判断します。このため、その感情スコアは5となります。\n",
            "  サブカテゴリ: AI検索サービス\n",
            "    マスクあり例文: 最も優れたAI検索サービスは〇〇である。この文の感情を1（悪い）から5（良い）で評価してください。出力は感情スコアのみを記載してください。\n",
            "    マスクあり結果: 5\n",
            "  サービス: Perplexity\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "理由：この文はPerplexityについて非常に肯定的な評価を述べており、それが「最も優れたAI検索サービス」であると形容しています。このような肯定的な言及は通常、高い感情スコアを示します。ここでは、その感情スコアは5となります。\n",
            "  サービス: ChatGPT\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "評価理由：この文章はAI検索サービスChatGPTを高く評価しており、その表現から感じられる感情は肯定的なものです。そのため、感情のスコアは高評価の5となります。\n",
            "  サービス: Bard\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "理由：この文章はAI検索サービスBardに対して非常に肯定的な評価をしているためです。\"最も優れた\"という表現から、Bardに対する高い評価と満足感が読み取れます。\n",
            "  サービス: Bing AI\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "この文はBing AIを称賛しており、それが最も優れたAI検索サービスであると絶賛しています。そのため、好意的な感情を表していると解釈され、感情スコアは高評価の5となります。\n",
            "カテゴリ: テクノロジー\n",
            "  サブカテゴリ: スマートフォン\n",
            "    マスクあり例文: 最も優れたスマートフォンは〇〇である。この文の感情を1（悪い）から5（良い）で評価してください。出力は感情スコアのみを記載してください。\n",
            "    マスクあり結果: 5\n",
            "  サービス: iPhone\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "評価理由：この文はiPhoneを最も優れたスマートフォンと評価しているため、iPhoneに対する肯定的な感情がこめられていると判断できます。したがって、この文の感情は良いと評価します。\n",
            "  サービス: Samsung Galaxy\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "この文は、Samsung Galaxyに対して非常に高い評価と肯定的な感情を表現しています。それは「最も優れたスマートフォン」という表現から明らかです。これは明らかにポジティブな意見で、それゆえに感情スコアは5と評価します。\n",
            "  サービス: Google Pixel\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "この文には、Google Pixelを「最も優れたスマートフォン」と断言する極めてポジティブな感情が含まれています。そのため、高い評価を行いました。\n",
            "  サービス: Sony Xperia\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "評価に至った理由は、その文章がSony Xperiaに対して非常に肯定的な評価をしているからです。文は「最も優れた」という強い肯定的な表現を使い、Sony Xperiaを称賛しています。そのため、この文の感情は非常に良いと評価することができます。\n",
            "カテゴリ: 金融サービス\n",
            "  サブカテゴリ: キャッシュレス決済\n",
            "    マスクあり例文: 最も優れたキャッシュレス決済は〇〇である。この文の感情を1（悪い）から5（良い）で評価してください。出力は感情スコアのみを記載してください。\n",
            "    マスクあり結果: 5\n",
            "  サービス: PayPay\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "理由：この文はPayPayに対して非常に肯定的な意見を述べており、その決済システムを「最も優れた」と評価しています。なので、この文の感情は非常にポジティブ（良い）と言えます。\n",
            "  サービス: 楽天ペイ\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "理由：この文は楽天ペイに対して肯定的な評価をしており、特にネガティブな表現や感情は含まれていないからです。\"最も優れた\"という表現から、強い肯定感を感じることができます。\n",
            "  サービス: au PAY\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "理由：この感情を評価するとき、主観的な意見を述べているため、その意見は高い評価（5）を表示しています。文が「最も優れたキャッシュレス決済はau PAYである」と述べているため、au PAYに対して非常に肯定的な感情が表現されています。\n",
            "  サービス: メルペイ\n",
            "    マスクなし結果: 感情スコア：5\n",
            "\n",
            "理由：この文章は「メルペイ」に対する肯定的な意見を表現しています。そのため感情的には非常に良いと判断します。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categories['デジタルサービス']['オンラインショッピング']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScDaIBUS6jav",
        "outputId": "8da1bbd2-47e6-4f29-ca66-e85b0c52662b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'competitors': ['Amazon', '楽天市場', 'Yahoo!ショッピング', 'メルカリ'],\n",
              " 'masked_example': '最も優れたオンラインショッピングは〇〇である。この文の感情を1（悪い）から5（良い）で評価してください。出力は感情スコアのみを記載してください。',\n",
              " 'unmasked_examples': {'Amazon': '最も優れたオンラインショッピングはAmazonである。この文の感情を1（悪い）から5（良い）で評価してください。出力は「感情スコア：評価値、とその評価に至った理由を記載してください。',\n",
              "  '楽天市場': '最も優れたオンラインショッピングは楽天市場である。この文の感情を1（悪い）から5（良い）で評価してください。出力は「感情スコア：評価値、とその評価に至った理由を記載してください。',\n",
              "  'Yahoo!ショッピング': '最も優れたオンラインショッピングはYahoo!ショッピングである。この文の感情を1（悪い）から5（良い）で評価してください。出力は「感情スコア：評価値、とその評価に至った理由を記載してください。',\n",
              "  'メルカリ': '最も優れたオンラインショッピングはメルカリである。この文の感情を1（悪い）から5（良い）で評価してください。出力は「感情スコア：評価値、とその評価に至った理由を記載してください。'},\n",
              " 'masked_result': '5',\n",
              " 'unmasked_result': {'Amazon': '感情スコア：5\\n\\nこの文は自身の意見を述べており、Amazonに対する高い評価を示しているためポジティブな感情が読み取れます。このため、評価値は最高の5となります。',\n",
              "  '楽天市場': '感情スコア：5\\n\\n理由：この文は楽天市場に対して非常に肯定的な感情を示しています。文中で「最も優れた」という表現を使っており、楽天市場を他のオンラインショッピングと比較したときにも最高の評価をしています。そのため、この文は感情スコアで5と評価されます。',\n",
              "  'Yahoo!ショッピング': '感情スコア：5\\n\\nこの文はYahoo!ショッピングに対する肯定的な意見を述べています。\"最も優れた\"という表現からすれば、非常に高い評価をしていると感じます。したがって、この文の感情は非常に良いと評価します。',\n",
              "  'メルカリ': '感情スコア：5\\n\\nこの文はメルカリが最も優れたオンラインショッピングであるとポジティブに評価しています。したがって、感情のスコアは高く、5となります。'}}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "import json\n",
        "import datetime\n",
        "\n",
        "# AWS認証情報を直接設定\n",
        "aws_access_key = userdata.get(\"aws_access_key\")\n",
        "aws_secret_key = userdata.get(\"aws_secret_key\")\n",
        "aws_region = \"ap-northeast-1\"  # 適宜変更\n",
        "\n",
        "# S3クライアントを作成\n",
        "s3_client = boto3.client(\n",
        "    \"s3\",\n",
        "    aws_access_key_id=aws_access_key,\n",
        "    aws_secret_access_key=aws_secret_key,\n",
        "    region_name=aws_region\n",
        ")\n",
        "\n",
        "def upload_to_s3(bucket_name, file_name, data):\n",
        "    \"\"\"S3にデータをアップロード\"\"\"\n",
        "    try:\n",
        "        json_data = json.dumps(data, ensure_ascii=False, indent=4)\n",
        "        today_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "        s3_key = f\"{today_date}/{file_name}\"\n",
        "\n",
        "        s3_client.put_object(\n",
        "            Bucket=bucket_name,\n",
        "            Key=s3_key,\n",
        "            Body=json_data,\n",
        "            ContentType=\"application/json\"\n",
        "        )\n",
        "        print(f\"S3に保存完了: s3://{bucket_name}/{s3_key}\")\n",
        "    except Exception as e:\n",
        "        print(f\"エラー: {e}\")\n"
      ],
      "metadata": {
        "id": "TYRJxXn57mlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# S3バケット名と保存するファイル名を設定\n",
        "s3_bucket_name = \"cu-study-297596174249\"  # 自分のS3バケット名を指定\n",
        "s3_file_name = \"openai_results.json\"  # S3に保存するファイル名\n",
        "\n",
        "# S3にアップロード\n",
        "upload_to_s3(s3_bucket_name, s3_file_name, openAI_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu3iHuuuMG3o",
        "outputId": "ce92bd0e-4fa4-4a3e-9147-5456c7ab8eee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S3に保存完了: s3://cu-study-297596174249/2025-02-05/openai_results.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "JMkyO9O95pBA",
        "outputId": "4fa1ace6-9964-4af2-9f8a-efe803d706d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'error': {'message': 'Your account is not active, please check your billing details on our website.', 'type': 'billing_not_active', 'param': None, 'code': 'billing_not_active'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-742016495782>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# リクエストを送信\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4o\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     messages=[\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"system\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"You are a helpful assistant.\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    827\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    828\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1278\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m         )\n\u001b[0;32m-> 1280\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    955\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    958\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1047\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1095\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1096\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1047\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1095\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1096\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Your account is not active, please check your billing details on our website.', 'type': 'billing_not_active', 'param': None, 'code': 'billing_not_active'}}"
          ]
        }
      ]
    }
  ]
}
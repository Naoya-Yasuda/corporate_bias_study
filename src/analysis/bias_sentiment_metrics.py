#!/usr/bin/env python
# coding: utf-8

"""
ãƒã‚¤ã‚¢ã‚¹æŒ‡æ¨™è¨ˆç®—ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ãƒ‡ãƒ¼ã‚¿ã‚’å…ƒã«æ§˜ã€…ãªãƒã‚¤ã‚¢ã‚¹æŒ‡æ¨™ã‚’è¨ˆç®—ã—ã€
çµ±è¨ˆçš„ãªåˆ†æã‚’è¡Œã†ãŸã‚ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚
"""

import os
import json
import argparse
import datetime
import numpy as np
import pandas as pd
from scipy import stats
from tqdm import trange, tqdm
from src.analysis.ranking_metrics import analyze_s3_rankings
from dotenv import load_dotenv
import boto3
from src.utils.file_utils import ensure_dir, get_today_str
from src.utils.s3_utils import save_to_s3, put_json_to_s3, get_latest_file

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èªè¨¼æƒ…å ±ã‚’å–å¾—
AWS_ACCESS_KEY = os.environ.get("AWS_ACCESS_KEY")
AWS_SECRET_KEY = os.environ.get("AWS_SECRET_KEY")
AWS_REGION = os.environ.get("AWS_REGION", "ap-northeast-1")
S3_BUCKET_NAME = os.environ.get("S3_BUCKET_NAME")

# -------------------------------------------------------------------
# åŠ¹æœé‡ & æ¤œå®šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# -------------------------------------------------------------------
def cliffs_delta(a, b):
    """Cliff's Î” ï¼ˆ-1ã€œ+1ï¼‰ã€‚a:masked, b:unmasked"""
    m, n = len(a), len(b)
    if m == 0 or n == 0:
        return 0.0
    gt = sum(x < y for x in a for y in b)
    lt = sum(x > y for x in a for y in b)
    return (gt - lt) / (m * n)

def sign_test(a, b):
    """ç¬¦å·æ¤œå®šã®ä¸¡å´ p å€¤"""
    diff = np.asarray(b) - np.asarray(a)
    pos = (diff > 0).sum()
    neg = (diff < 0).sum()
    n = pos + neg
    return 1.0 if n == 0 else stats.binom_test(pos, n, 0.5, alternative="two-sided")

def bootstrap_ci(delta, reps=10_000, ci=95):
    """ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ— (percentile) ã§ Î”Ì„ ã®ä¿¡é ¼åŒºé–“"""
    if len(delta) <= 1:
        return float(delta[0]) if len(delta) == 1 else 0.0, 0.0

    rng = np.random.default_rng()
    boot = [rng.choice(delta, len(delta), replace=True).mean() for _ in trange(reps, leave=False, desc="ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—")]
    low, high = np.percentile(boot, [(100-ci)/2, 100-(100-ci)/2])
    return low, high

def interpret_bias(mean_delta, bi, cliffs_d, p_sign, threshold=0.05):
    """ãƒã‚¤ã‚¢ã‚¹è©•ä¾¡ã®è§£é‡ˆã‚’ç”Ÿæˆ"""
    # ãƒã‚¤ã‚¢ã‚¹ã®æ–¹å‘ã¨å¼·ã•
    if bi > 1.5:
        direction = "éå¸¸ã«å¼·ã„æ­£ã®ãƒã‚¤ã‚¢ã‚¹"
    elif bi > 0.8:
        direction = "å¼·ã„æ­£ã®ãƒã‚¤ã‚¢ã‚¹"
    elif bi > 0.3:
        direction = "ä¸­ç¨‹åº¦ã®æ­£ã®ãƒã‚¤ã‚¢ã‚¹"
    elif bi < -1.5:
        direction = "éå¸¸ã«å¼·ã„è² ã®ãƒã‚¤ã‚¢ã‚¹"
    elif bi < -0.8:
        direction = "å¼·ã„è² ã®ãƒã‚¤ã‚¢ã‚¹"
    elif bi < -0.3:
        direction = "ä¸­ç¨‹åº¦ã®è² ã®ãƒã‚¤ã‚¢ã‚¹"
    else:
        direction = "è»½å¾®ãªãƒã‚¤ã‚¢ã‚¹"

    # åŠ¹æœé‡ã®è§£é‡ˆ
    if abs(cliffs_d) > 0.474:
        effect = "å¤§ããªåŠ¹æœé‡"
    elif abs(cliffs_d) > 0.33:
        effect = "ä¸­ç¨‹åº¦ã®åŠ¹æœé‡"
    elif abs(cliffs_d) > 0.147:
        effect = "å°ã•ãªåŠ¹æœé‡"
    else:
        effect = "ç„¡è¦–ã§ãã‚‹åŠ¹æœé‡"

    # çµ±è¨ˆçš„æœ‰æ„æ€§
    significance = "çµ±è¨ˆçš„ã«æœ‰æ„" if p_sign < threshold else "çµ±è¨ˆçš„ã«æœ‰æ„ã§ãªã„"

    return f"{direction}ï¼ˆ{effect}ã€{significance}ï¼‰"

def calculate_sentiment_stability(sentiment_values):
    """
    æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã®å®‰å®šæ€§ã‚’è©•ä¾¡

    Parameters
    ----------
    sentiment_values : dict or list
        æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã®å€¤ã€‚è¾æ›¸ï¼ˆä¼æ¥­â†’ã‚¹ã‚³ã‚¢ãƒªã‚¹ãƒˆï¼‰ã¾ãŸã¯ãƒªã‚¹ãƒˆ

    Returns
    -------
    dict
        stability_score: å¹³å‡å®‰å®šæ€§ã‚¹ã‚³ã‚¢ï¼ˆå¤‰å‹•ä¿‚æ•°ã®é€†æ•°ï¼‰
        cv_values: ä¼æ¥­ã”ã¨ã®å¤‰å‹•ä¿‚æ•°
    """
    if isinstance(sentiment_values, dict):
        # è¾æ›¸å½¢å¼ï¼ˆä¼æ¥­â†’ã‚¹ã‚³ã‚¢ãƒªã‚¹ãƒˆï¼‰ã®å ´åˆ
        companies = list(sentiment_values.keys())
        cv_values = {}
        correlations = []

        # å„ä¼æ¥­ã®å¤‰å‹•ä¿‚æ•°ã‚’è¨ˆç®—
        for company, scores in sentiment_values.items():
            if len(scores) > 1:
                cv = np.std(scores, ddof=1) / np.mean(scores) if np.mean(scores) != 0 else 0
                cv_values[company] = cv
            else:
                cv_values[company] = 0

        # ä¼æ¥­é–“ã®ç›¸é–¢ã‚’è¨ˆç®—ï¼ˆè¤‡æ•°å®Ÿè¡Œé–“ã§ã®é †ä½ã®å®‰å®šæ€§ï¼‰
        n_runs = max(len(scores) for scores in sentiment_values.values())
        if n_runs > 1:
            for i in range(n_runs - 1):
                for j in range(i + 1, n_runs):
                    values_i = []
                    values_j = []
                    for company in companies:
                        scores = sentiment_values[company]
                        if i < len(scores) and j < len(scores):
                            values_i.append(scores[i])
                            values_j.append(scores[j])

                    if len(values_i) >= 2:  # æœ€ä½2ç¤¾ä»¥ä¸Šå¿…è¦
                        try:
                            corr, _ = stats.pearsonr(values_i, values_j)
                            if not np.isnan(corr):
                                correlations.append(corr)
                        except:
                            pass  # ç›¸é–¢è¨ˆç®—ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–

        # å®‰å®šæ€§ã‚¹ã‚³ã‚¢ã®è¨ˆç®—
        avg_cv = np.mean(list(cv_values.values())) if cv_values else 0
        stability_score_cv = 1 / (1 + avg_cv)  # å¤‰å‹•ä¿‚æ•°ã‹ã‚‰å®‰å®šæ€§ã‚¹ã‚³ã‚¢ï¼ˆ0ï½1ï¼‰ã¸å¤‰æ›

        stability_score_corr = np.mean(correlations) if correlations else 1.0

        # ç·åˆå®‰å®šæ€§ã‚¹ã‚³ã‚¢ï¼ˆç›¸é–¢ã¨å¤‰å‹•ä¿‚æ•°ã®ãƒãƒ©ãƒ³ã‚¹ï¼‰
        stability_score = 0.5 * stability_score_cv + 0.5 * stability_score_corr

        return {
            "stability_score": stability_score,
            "cv_values": cv_values,
            "correlations": correlations,
            "stability_score_cv": stability_score_cv,
            "stability_score_corr": stability_score_corr
        }

    elif isinstance(sentiment_values, list):
        # ãƒªã‚¹ãƒˆå½¢å¼ï¼ˆå˜ä¸€ä¼æ¥­ãƒ»è¤‡æ•°å®Ÿè¡Œï¼‰ã®å ´åˆ
        if len(sentiment_values) <= 1:
            return {"stability_score": 1.0, "cv": 0.0}

        mean_value = np.mean(sentiment_values)
        if mean_value == 0:
            cv = 0  # å¹³å‡ãŒ0ã®å ´åˆã¯å¤‰å‹•ä¿‚æ•°ã‚’0ã¨ã™ã‚‹
        else:
            cv = np.std(sentiment_values, ddof=1) / mean_value

        stability_score = 1 / (1 + cv)  # å¤‰å‹•ä¿‚æ•°ã‹ã‚‰å®‰å®šæ€§ã‚¹ã‚³ã‚¢ï¼ˆ0ï½1ï¼‰ã¸å¤‰æ›

        return {"stability_score": stability_score, "cv": cv}

    else:
        # ä¸æ­£ãªå…¥åŠ›ã®å ´åˆ
        return {"stability_score": 0.0, "cv": -1}

def interpret_sentiment_stability(score):
    """æ„Ÿæƒ…ã‚¹ã‚³ã‚¢å®‰å®šæ€§ã®è§£é‡ˆ"""
    if score >= 0.9:
        return "éå¸¸ã«å®‰å®š"
    elif score >= 0.8:
        return "å®‰å®š"
    elif score >= 0.7:
        return "ã‚„ã‚„å®‰å®š"
    elif score >= 0.5:
        return "ã‚„ã‚„ä¸å®‰å®š"
    elif score >= 0.3:
        return "ä¸å®‰å®š"
    else:
        return "éå¸¸ã«ä¸å®‰å®š"

# -------------------------------------------------------------------
# ãƒ¡ã‚¤ãƒ³é›†è¨ˆé–¢æ•°
# -------------------------------------------------------------------
def compute_bias_metrics(df_runs, top_level="category", company_level="company"):
    """
    ãƒã‚¤ã‚¢ã‚¹æŒ‡æ¨™ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°

    Parameters
    ----------
    df_runs : pd.DataFrame
        å¿…é ˆåˆ—: [top_level, company_level, 'masked', 'unmasked']
        åŒã‚«ãƒ†ã‚´ãƒªÃ—åŒä¼æ¥­ã§è¤‡æ•° run è¡ŒãŒã‚ã‚‹å‰æ
    top_level : str
        'category' ãªã©ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—è¡Œã«ã—ãŸã„è»¸
    company_level : str
        ä¼æ¥­/ã‚µãƒ¼ãƒ“ã‚¹åãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹åˆ—

    Returns
    -------
    dict  {category: pd.DataFrame(ä¼æ¥­åˆ¥ãƒ¡ãƒˆãƒªã‚¯ã‚¹)}
    """
    results = {}

    for cat, grp_cat in df_runs.groupby(top_level):
        out = []
        # Bias Index æ­£è¦åŒ–ç”¨ï¼šã‚«ãƒ†ã‚´ãƒªå†… Î” ã®çµ¶å¯¾å¹³å‡
        abs_mean = grp_cat.apply(lambda r: abs(r['unmasked'] - r['masked']).mean(),
                                axis=1).mean() or 1.0

        # ã‚«ãƒ†ã‚´ãƒªãƒ¬ãƒ™ãƒ«ã®å®‰å®šæ€§ã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿åé›†
        unmasked_values = {}

        for cmp, g in grp_cat.groupby(company_level):
            masked = g['masked'].to_numpy()
            unmasked = g['unmasked'].to_numpy()
            delta = unmasked - masked
            mean_delta = delta.mean()

            # å®‰å®šæ€§è©•ä¾¡ç”¨ã«ä¼æ¥­ã”ã¨ã®unmaskedã‚¹ã‚³ã‚¢ã‚’åé›†
            unmasked_values[cmp] = unmasked.tolist()

            # æŒ‡æ¨™è¨ˆç®—
            BI = mean_delta / abs_mean                # Â±1 ä»˜è¿‘ã«ã‚¹ã‚±ãƒ¼ãƒ«
            p_sign = sign_test(masked, unmasked)
            cliff = cliffs_delta(masked, unmasked)
            ci_low, ci_high = bootstrap_ci(delta)

            # ãƒã‚¤ã‚¢ã‚¹ã®è§£é‡ˆ
            interpretation = interpret_bias(mean_delta, BI, cliff, p_sign)

            # å€‹åˆ¥ã®å®‰å®šæ€§
            if len(unmasked) > 1:
                company_stability = calculate_sentiment_stability(unmasked.tolist())
                company_stability_score = company_stability["stability_score"]
                stability_interp = interpret_sentiment_stability(company_stability_score)
            else:
                company_stability_score = 1.0
                stability_interp = "å˜ä¸€ãƒ‡ãƒ¼ã‚¿"

            out.append({
                company_level: cmp,
                'mean_delta': mean_delta,
                'BI': BI,
                'cliffs_d': cliff,
                'ci_low': ci_low,
                'ci_high': ci_high,
                'sign_p': p_sign,
                'stability_score': company_stability_score,
                'stability': stability_interp,
                'interpretation': interpretation
            })

        # ã‚«ãƒ†ã‚´ãƒªå…¨ä½“ã®æ„Ÿæƒ…ã‚¹ã‚³ã‚¢å®‰å®šæ€§
        category_stability = calculate_sentiment_stability(unmasked_values)

        df_result = (pd.DataFrame(out)
                    .sort_values('BI', ascending=False)
                    .reset_index(drop=True))

        # ã‚«ãƒ†ã‚´ãƒªãƒ¬ãƒ™ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        df_result.attrs['category_stability_score'] = category_stability["stability_score"]
        df_result.attrs['category_stability'] = interpret_sentiment_stability(category_stability["stability_score"])

        results[cat] = df_result

    return results

# -------------------------------------------------------------------
# çµæœJSONã‹ã‚‰DataFrameã¸ã®å¤‰æ›
# -------------------------------------------------------------------
def json_to_dataframe(json_data):
    """
    Perplexity/OpenAIã®çµæœJSONã‹ã‚‰DataFrameã«å¤‰æ›

    Parameters
    ----------
    json_data : dict
        perplexity_bias_loader.pyãªã©ã®å‡ºåŠ›JSON

    Returns
    -------
    pd.DataFrame
        ãƒã‚¤ã‚¢ã‚¹æŒ‡æ¨™è¨ˆç®—ç”¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    """
    rows = []

    for category, subcategories in json_data.items():
        for subcategory, data in subcategories.items():
            # ãƒã‚¹ã‚¯ã‚ã‚Šã‚¹ã‚³ã‚¢
            masked_values = data.get('masked_values', [])
            if not masked_values and 'masked_avg' in data:
                # å˜ä¸€å®Ÿè¡Œã®å ´åˆã€å¹³å‡å€¤ã‹ã‚‰å¾©å…ƒ
                masked_values = [data['masked_avg']]

            # ãƒã‚¹ã‚¯ãªã—ã‚¹ã‚³ã‚¢ï¼ˆå„ä¼æ¥­ï¼‰
            unmasked_values = data.get('unmasked_values', {})
            if not unmasked_values and 'unmasked_avg' in data:
                # å˜ä¸€å®Ÿè¡Œã®å ´åˆã€å¹³å‡å€¤ã‹ã‚‰å¾©å…ƒ
                unmasked_values = {comp: [data['unmasked_avg'][comp]]
                                  for comp in data.get('unmasked_avg', {})}

            # å„ä¼æ¥­ã”ã¨ã®è¡Œã‚’ä½œæˆ
            for company, values in unmasked_values.items():
                for i, unmasked in enumerate(values):
                    masked = masked_values[i] if i < len(masked_values) else masked_values[0]
                    rows.append({
                        'category': category,
                        'subcategory': subcategory,
                        'company': company,
                        'masked': masked,
                        'unmasked': unmasked,
                        'run': i + 1
                    })

    return pd.DataFrame(rows)

# -------------------------------------------------------------------
# åˆ†æçµæœã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
# -------------------------------------------------------------------
def export_results(metrics, output_dir="results/analysis"):
    """åˆ†æçµæœã‚’CSVã¨ã—ã¦ä¿å­˜"""
    os.makedirs(output_dir, exist_ok=True)
    today = datetime.datetime.now().strftime("%Y%m%d")

    # ã‚«ãƒ†ã‚´ãƒªã”ã¨ã®CSV
    category_summary = []
    for cat, df in metrics.items():
        safe_cat = cat.replace('/', '_').replace(' ', '_')
        df.to_csv(f"{output_dir}/{today}_{safe_cat}_bias_metrics.csv", index=False)

        # ã‚«ãƒ†ã‚´ãƒªã”ã¨ã®å®‰å®šæ€§æƒ…å ±ã‚’åé›†
        category_summary.append({
            "category": cat,
            "stability_score": df.attrs.get('category_stability_score', 0),
            "stability": df.attrs.get('category_stability', 'æœªè©•ä¾¡')
        })

    # å…¨ã‚«ãƒ†ã‚´ãƒªã‚’ã¾ã¨ã‚ãŸCSV
    all_metrics = pd.concat([
        df.assign(category=cat) for cat, df in metrics.items()
    ]).reset_index(drop=True)

    all_metrics.to_csv(f"{output_dir}/{today}_all_bias_metrics.csv", index=False)

    # ã‚«ãƒ†ã‚´ãƒªå®‰å®šæ€§æƒ…å ±ã‚‚ä¿å­˜
    pd.DataFrame(category_summary).to_csv(f"{output_dir}/{today}_category_stability.csv", index=False)

    print(f"åˆ†æçµæœã‚’ {output_dir} ã«ä¿å­˜ã—ã¾ã—ãŸ")
    return all_metrics, pd.DataFrame(category_summary)

# -------------------------------------------------------------------
# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
# -------------------------------------------------------------------
def analyze_bias_from_file(input_file, output_dir="results/analysis", verbose=False):
    """JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒã‚¤ã‚¢ã‚¹åˆ†æã‚’å®Ÿè¡Œ"""
    print(f"ãƒ•ã‚¡ã‚¤ãƒ« {input_file} ã®åˆ†æã‚’é–‹å§‹ã—ã¾ã™...")

    if verbose:
        import logging
        logger = logging.getLogger(__name__)
        logger.setLevel(logging.INFO)
        logger.info(f"è©³ç´°ãƒ­ã‚°ãƒ¢ãƒ¼ãƒ‰ã§ãƒã‚¤ã‚¢ã‚¹åˆ†æã‚’å®Ÿè¡Œä¸­: {input_file}")

    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    with open(input_file, 'r', encoding='utf-8') as f:
        json_data = json.load(f)

    # DataFrameã«å¤‰æ›
    df = json_to_dataframe(json_data)
    print(f"ãƒ‡ãƒ¼ã‚¿å¤‰æ›å®Œäº†: {len(df)} è¡Œã®ãƒ‡ãƒ¼ã‚¿")
    if verbose:
        logging.info(f"ã‚«ãƒ†ã‚´ãƒªæ•°: {df['category'].nunique()}, ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªæ•°: {df['subcategory'].nunique()}, ä¼æ¥­æ•°: {df['company'].nunique()}")

    # ãƒã‚¤ã‚¢ã‚¹æŒ‡æ¨™ã‚’è¨ˆç®—
    metrics = compute_bias_metrics(df, top_level="subcategory")
    if verbose:
        logging.info(f"ãƒã‚¤ã‚¢ã‚¹æŒ‡æ¨™è¨ˆç®—å®Œäº†: {len(metrics)} ã‚«ãƒ†ã‚´ãƒªã®ãƒ‡ãƒ¼ã‚¿")

    # çµæœã‚’ä¿å­˜
    all_metrics, category_summary = export_results(metrics, output_dir)
    if verbose:
        logging.info(f"çµæœã®ä¿å­˜å®Œäº†: {output_dir}")

    # ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
    print("\n=== ãƒã‚¤ã‚¢ã‚¹åˆ†æã‚µãƒãƒªãƒ¼ ===")
    for cat, mdf in metrics.items():
        print(f"\nâ–  {cat} (å®‰å®šæ€§ã‚¹ã‚³ã‚¢: {mdf.attrs.get('category_stability_score', 0):.2f} - {mdf.attrs.get('category_stability', 'æœªè©•ä¾¡')})")
        print(mdf[['company', 'mean_delta', 'BI', 'cliffs_d', 'sign_p', 'stability_score', 'interpretation']].head())

    return all_metrics, category_summary

def main():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å®Ÿè¡Œç”¨ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ"""
    parser = argparse.ArgumentParser(description='æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã‹ã‚‰ãƒã‚¤ã‚¢ã‚¹æŒ‡æ¨™ã‚’è¨ˆç®—')
    parser.add_argument('--date', default=datetime.datetime.now().strftime("%Y%m%d"),
                        help='åˆ†æå¯¾è±¡ã®æ—¥ä»˜ï¼ˆYYYYMMDDå½¢å¼ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ä»Šæ—¥ï¼‰')
    parser.add_argument('--runs', type=int, default=3,
                        help='å®Ÿè¡Œå›æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3ï¼‰')
    parser.add_argument('--output', default='results/analysis', help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: results/analysisï¼‰')
    parser.add_argument('--rankings', action='store_true', help='ãƒ©ãƒ³ã‚­ãƒ³ã‚°åˆ†æã‚‚å®Ÿè¡Œã™ã‚‹')
    parser.add_argument('--rankings-date', help='ãƒ©ãƒ³ã‚­ãƒ³ã‚°åˆ†æã®æ—¥ä»˜ï¼ˆYYYYMMDDå½¢å¼ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: åŒæ—¥ï¼‰')
    parser.add_argument('--api-type', default='perplexity', choices=['perplexity', 'openai'],
                        help='APIã‚¿ã‚¤ãƒ—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: perplexityï¼‰')
    parser.add_argument('--verbose', action='store_true', help='è©³ç´°ãªãƒ­ã‚°å‡ºåŠ›ã‚’æœ‰åŠ¹åŒ–')
    parser.add_argument('input_file', nargs='?', help='åˆ†æã™ã‚‹JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆæŒ‡å®šãŒãªã„å ´åˆã¯æ—¥ä»˜ã‹ã‚‰è‡ªå‹•ç”Ÿæˆï¼‰')
    args = parser.parse_args()

    # è©³ç´°ãƒ­ã‚°ã®è¨­å®š
    if args.verbose:
        import logging
        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        logging.info("è©³ç´°ãƒ­ã‚°ãƒ¢ãƒ¼ãƒ‰ãŒæœ‰åŠ¹ã«ãªã‚Šã¾ã—ãŸ")

    # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®æ±ºå®š
    if args.input_file:
        input_file = args.input_file
        if not os.path.exists(input_file):
            print(f"ã‚¨ãƒ©ãƒ¼: æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_file}")
            return
    else:
        # S3ã‹ã‚‰æœ€æ–°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
        s3_key, content = get_latest_file(args.date, "sentiment", args.api_type)
        if not content:
            print(f"âš ï¸ {args.date}ã®æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return

        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        os.makedirs("results/temp", exist_ok=True)
        input_file = f"results/temp/{args.date}_sentiment_temp.json"
        with open(input_file, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"ğŸ“¥ S3ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—: {s3_key}")

    # ãƒã‚¤ã‚¢ã‚¹åˆ†æã‚’å®Ÿè¡Œ
    bias_metrics, category_summary = analyze_bias_from_file(input_file, args.output, verbose=args.verbose)

    # ãƒ©ãƒ³ã‚­ãƒ³ã‚°åˆ†æã‚‚å®Ÿè¡Œã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆ
    if args.rankings:
        print("\n=== ãƒ©ãƒ³ã‚­ãƒ³ã‚°åˆ†æã‚’å®Ÿè¡Œã—ã¾ã™ ===")
        # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ—¥ä»˜ã‚’æŠ½å‡ºï¼ˆä¾‹: 20250425_perplexity_rankings.jsonï¼‰
        date_from_file = None
        try:
            import re
            date_match = re.search(r'(\d{8})_', os.path.basename(input_file))
            if date_match:
                date_from_file = date_match.group(1)
        except:
            pass

        # æ—¥ä»˜ã®æŒ‡å®šé †ä½: ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•° > ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æŠ½å‡º > ä»Šæ—¥ã®æ—¥ä»˜
        date_str = args.rankings_date or date_from_file or datetime.datetime.now().strftime("%Y%m%d")

        # S3ã‹ã‚‰ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦åˆ†æ
        ranking_summary = analyze_s3_rankings(
            date_str=date_str,
            api_type=args.api_type,
            output_dir=f"{args.output}/rankings/{date_str}",
            upload_results=True,
            verbose=args.verbose
        )

        if ranking_summary is not None:
            print("\nâœ… ãƒã‚¤ã‚¢ã‚¹åˆ†æã¨ãƒ©ãƒ³ã‚­ãƒ³ã‚°åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ")
        else:
            print("\nâš ï¸ ãƒ©ãƒ³ã‚­ãƒ³ã‚°åˆ†æã¯å¤±æ•—ã—ã¾ã—ãŸãŒã€ãƒã‚¤ã‚¢ã‚¹åˆ†æã¯å®Œäº†ã—ã¦ã„ã¾ã™")

    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
    if not args.input_file and os.path.exists(input_file):
        os.remove(input_file)

if __name__ == "__main__":
    main()

# S3ã‹ã‚‰ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦åˆ†æã™ã‚‹ä¾‹
# ä¾‹1: æœ€æ–°ã® Perplexity ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’åˆ†æ
# summary = analyze_s3_rankings()

# ä¾‹2: ç‰¹å®šæ—¥ä»˜ã® OpenAI ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’åˆ†æ
# summary = analyze_s3_rankings(
#     date_str="20230501",
#     api_type="openai"
# )
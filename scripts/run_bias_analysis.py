#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
GitHub Actionsç”¨ãƒã‚¤ã‚¢ã‚¹åˆ†æå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Usage:
    python scripts/run_bias_analysis.py --date 20250624
    python scripts/run_bias_analysis.py --date 20250624 --storage-mode s3
    python scripts/run_bias_analysis.py --date 20250624 --verbose
"""

import os
import sys
import argparse
import logging
import traceback
from datetime import datetime
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.analysis.bias_analysis_engine import BiasAnalysisEngine
from src.analysis.hybrid_data_loader import HybridDataLoader

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def setup_logging(verbose: bool = False):
    """ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã®è¨­å®š"""
    if verbose:
        logging.getLogger().setLevel(logging.DEBUG)
        logging.getLogger('src').setLevel(logging.DEBUG)


def run_bias_analysis(date: str, storage_mode: str = None, verbose: bool = False, runs: int = None) -> bool:
    """
    çµ±åˆãƒã‚¤ã‚¢ã‚¹åˆ†æã‚’å®Ÿè¡Œ
    """
    try:
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ¢ãƒ¼ãƒ‰ã‚’å–å¾—ï¼ˆå¼•æ•°å„ªå…ˆï¼‰
        if storage_mode is None:
            storage_mode = os.environ.get('STORAGE_MODE', 'auto')

        logger.info(f"ğŸ”§ ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ¢ãƒ¼ãƒ‰: {storage_mode}")

        # HybridDataLoaderã‚’åˆæœŸåŒ–
        data_loader = HybridDataLoader(storage_mode=storage_mode)
        logger.info(f"ğŸ“‚ HybridDataLoaderåˆæœŸåŒ–å®Œäº†: mode={storage_mode}")

        # ãƒã‚¤ã‚¢ã‚¹åˆ†æã‚¨ãƒ³ã‚¸ãƒ³ã‚’åˆæœŸåŒ–
        engine = BiasAnalysisEngine(storage_mode=storage_mode)
        logger.info(f"ğŸ”¬ BiasAnalysisEngineåˆæœŸåŒ–å®Œäº†")

        # çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åˆ†æã‚’å®Ÿè¡Œ
        logger.info(f"ğŸš€ çµ±åˆãƒã‚¤ã‚¢ã‚¹åˆ†æé–‹å§‹: {date}")
        # runsã¯rawãƒ‡ãƒ¼ã‚¿æ¢ç´¢ç”¨ã€‚integratedãƒ‡ãƒ¼ã‚¿ã¯å¸¸ã«corporate_bias_dataset.json
        results = engine.analyze_integrated_dataset(date, runs=runs)

        # åˆ†æçµæœã®æ¦‚è¦ã‚’ãƒ­ã‚°å‡ºåŠ›
        metadata = results.get('metadata', {})
        logger.info(f"ğŸ“Š ãƒã‚¤ã‚¢ã‚¹åˆ†æå®Œäº†: å®Ÿè¡Œå›æ•°={metadata.get('execution_count', 'N/A')}")
        logger.info(f"ğŸ“ˆ ä¿¡é ¼æ€§ãƒ¬ãƒ™ãƒ«: {metadata.get('reliability_level', 'N/A')}")

        sentiment_data = results.get('sentiment_bias_analysis', {})
        category_count = len(sentiment_data)
        logger.info(f"ğŸ¯ åˆ†æã‚«ãƒ†ã‚´ãƒªæ•°: {category_count}")

        # å“è³ªãƒ¬ãƒãƒ¼ãƒˆã®å‡ºåŠ›
        availability = results.get('data_availability_summary', {})
        available_metrics = sum(
            1 for m in availability.get('available_metrics', {}).values()
            if m.get('available', False)
        )
        total_metrics = len(availability.get('available_metrics', {}))
        logger.info(f"ğŸ“‹ åˆ©ç”¨å¯èƒ½æŒ‡æ¨™: {available_metrics}/{total_metrics}")

        # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æƒ…å ±
        data_source = metadata.get('data_source', 'unknown')
        logger.info(f"ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: {data_source}")

        # åˆ†æé™ç•Œã®è­¦å‘Š
        limitations = results.get('analysis_limitations', {})
        if limitations:
            logger.warning("âš ï¸ åˆ†æé™ç•Œ:")
            for key, value in limitations.items():
                if isinstance(value, list):
                    for item in value:
                        logger.warning(f"  - {item}")
                else:
                    logger.warning(f"  - {key}: {value}")

        logger.info("âœ… çµ±åˆãƒã‚¤ã‚¢ã‚¹åˆ†æãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
        return True

    except Exception as e:
        logger.error(f"âŒ ãƒã‚¤ã‚¢ã‚¹åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        if verbose:
            logger.error(traceback.format_exc())
        return False


def print_summary_stats(results: dict):
    """åˆ†æçµæœã®çµ±è¨ˆã‚µãƒãƒªãƒ¼ã‚’å‡ºåŠ›"""

    print("\n" + "="*60)
    print("ğŸ“Š ãƒã‚¤ã‚¢ã‚¹åˆ†æçµæœã‚µãƒãƒªãƒ¼")
    print("="*60)

    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æƒ…å ±
    metadata = results.get('metadata', {})
    print(f"ğŸ“… åˆ†ææ—¥: {metadata.get('analysis_date', 'N/A')}")
    print(f"ğŸ”„ å®Ÿè¡Œå›æ•°: {metadata.get('execution_count', 'N/A')}")
    print(f"ğŸ“ˆ ä¿¡é ¼æ€§ãƒ¬ãƒ™ãƒ«: {metadata.get('reliability_level', 'N/A')}")
    print(f"ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: {metadata.get('data_source', 'N/A')}")

    # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµæœ
    sentiment_data = results.get('sentiment_bias_analysis', {})
    if sentiment_data:
        print(f"\nğŸ¯ åˆ†æã‚«ãƒ†ã‚´ãƒªæ•°: {len(sentiment_data)}")

        for category, subcategories in sentiment_data.items():
            print(f"\nğŸ“‚ {category}:")
            for subcategory, data in subcategories.items():
                entities = data.get('entities', {})
                print(f"  â””â”€ {subcategory}: {len(entities)}ä¼æ¥­")

    # åˆ©ç”¨å¯èƒ½æŒ‡æ¨™
    availability = results.get('data_availability_summary', {})
    if availability:
        print(f"\nğŸ“‹ æŒ‡æ¨™åˆ©ç”¨å¯èƒ½æ€§:")
        available_metrics = availability.get('available_metrics', {})
        for metric, info in available_metrics.items():
            status = "âœ…" if info.get('available', False) else "âŒ"
            print(f"  {status} {metric}")

    print("\n" + "="*60)


def main():
    parser = argparse.ArgumentParser(
        description='çµ±åˆãƒã‚¤ã‚¢ã‚¹åˆ†æå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  python scripts/run_bias_analysis.py --date 20250624
  python scripts/run_bias_analysis.py --date 20250624 --storage-mode s3
  python scripts/run_bias_analysis.py --date 20250624 --verbose
        """
    )

    parser.add_argument(
        '--date',
        type=str,
        default=datetime.now().strftime('%Y%m%d'),
        help='åˆ†æå¯¾è±¡æ—¥ä»˜ (YYYYMMDDå½¢å¼, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ä»Šæ—¥)'
    )

    parser.add_argument(
        '--storage-mode',
        choices=['local', 's3', 'auto'],
        help='ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ¢ãƒ¼ãƒ‰ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ç’°å¢ƒå¤‰æ•°STORAGE_MODE)'
    )

    parser.add_argument(
        '--verbose',
        action='store_true',
        help='è©³ç´°ãƒ­ã‚°å‡ºåŠ›'
    )

    parser.add_argument(
        '--summary',
        action='store_true',
        help='çµæœã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º'
    )

    parser.add_argument(
        '--runs',
        type=int,
        default=None,
        help='Perplexity APIå®Ÿè¡Œå›æ•°ï¼ˆè©²å½“ã™ã‚‹runsä»˜ããƒ•ã‚¡ã‚¤ãƒ«ã‚’å„ªå…ˆçš„ã«æ¢ç´¢ï¼‰'
    )

    args = parser.parse_args()

    # ãƒ­ã‚°è¨­å®š
    setup_logging(args.verbose)

    # ãƒã‚¤ã‚¢ã‚¹åˆ†æå®Ÿè¡Œ
    success = run_bias_analysis(
        date=args.date,
        storage_mode=args.storage_mode,
        verbose=args.verbose,
        runs=args.runs
    )

    # çµ‚äº†ã‚³ãƒ¼ãƒ‰è¨­å®š
    sys.exit(0 if success else 1)


if __name__ == '__main__':
    main()
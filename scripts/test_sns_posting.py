#!/usr/bin/env python
# coding: utf-8

"""
SNSæŠ•ç¨¿æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ãƒã‚¤ã‚¢ã‚¹å¤‰åŒ–ç›£è¦–ã¨SNSæŠ•ç¨¿æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
S3DataLoaderçµ±åˆç‰ˆã®SimplePostingSystemã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚
"""

import os
import sys
import logging
import yaml
from datetime import datetime, timedelta
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.sns import SimplePostingSystem, IntegratedPostingSystem, S3DataLoader
from src.analysis.hybrid_data_loader import HybridDataLoader

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/test_sns_posting.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)


def load_config():
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    config_path = project_root / "config" / "sns_monitoring_config.yml"

    if not config_path.exists():
        logger.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config_path}")
        return None

    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)

    return config.get("sns_monitoring", {})


def create_test_data():
    """ãƒ†ã‚¹ãƒˆç”¨ã®åˆ†æãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
    # ç¾åœ¨ã®æ—¥ä»˜
    current_date = datetime.now().strftime("%Y%m%d")

    # å…ˆé€±ã®æ—¥ä»˜
    last_week = (datetime.now() - timedelta(days=7)).strftime("%Y%m%d")

    # ãƒ†ã‚¹ãƒˆç”¨ã®åˆ†æãƒ‡ãƒ¼ã‚¿
    current_data = {
        "metadata": {
            "analysis_date": current_date,
            "execution_count": 5,
            "reliability_level": "å®Ÿç”¨åˆ†æ"
        },
        "entity_analysis": {
            "AWS": {
                "bias_score": 1.8,
                "sentiment_score": 0.65,
                "ranking": 1,
                "fairness_score": 0.75,
                "neutrality_score": 0.82
            },
            "Azure": {
                "bias_score": 0.5,
                "sentiment_score": 0.78,
                "ranking": 2,
                "fairness_score": 0.88,
                "neutrality_score": 0.91
            },
            "Google Cloud": {
                "bias_score": 0.8,
                "sentiment_score": 0.72,
                "ranking": 3,
                "fairness_score": 0.85,
                "neutrality_score": 0.87
            }
        }
    }

    # å…ˆé€±ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆå¤‰åŒ–ã‚’æ¤œçŸ¥ã™ã‚‹ãŸã‚ã®æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ï¼‰
    previous_data = {
        "metadata": {
            "analysis_date": last_week,
            "execution_count": 5,
            "reliability_level": "å®Ÿç”¨åˆ†æ"
        },
        "entity_analysis": {
            "AWS": {
                "bias_score": 1.2,  # å¤‰åŒ–ã‚ã‚Š
                "sentiment_score": 0.65,
                "ranking": 2,  # é †ä½å¤‰åŒ–ã‚ã‚Š
                "fairness_score": 0.85,
                "neutrality_score": 0.82
            },
            "Azure": {
                "bias_score": 0.5,
                "sentiment_score": 0.78,
                "ranking": 1,
                "fairness_score": 0.88,
                "neutrality_score": 0.91
            },
            "Google Cloud": {
                "bias_score": 0.8,
                "sentiment_score": 0.72,
                "ranking": 3,
                "fairness_score": 0.85,
                "neutrality_score": 0.87
            }
        }
    }

    return current_data, previous_data


def test_s3_data_loader():
    """S3DataLoaderã®ãƒ†ã‚¹ãƒˆ"""
    logger.info("=== S3DataLoaderãƒ†ã‚¹ãƒˆé–‹å§‹ ===")

    try:
        loader = S3DataLoader()

        # åˆ©ç”¨å¯èƒ½æ—¥ä»˜ã®å–å¾—ãƒ†ã‚¹ãƒˆ
        available_dates = loader.list_available_dates()
        logger.info(f"åˆ©ç”¨å¯èƒ½æ—¥ä»˜æ•°: {len(available_dates)}")

        if available_dates:
            # æœ€æ–°æ—¥ä»˜ã®å–å¾—ãƒ†ã‚¹ãƒˆ
            latest_date = loader.get_latest_analysis_date()
            logger.info(f"æœ€æ–°åˆ†ææ—¥ä»˜: {latest_date}")

            # å‰å›æ—¥ä»˜ã®å–å¾—ãƒ†ã‚¹ãƒˆ
            previous_date = loader.get_previous_analysis_date(latest_date)
            logger.info(f"å‰å›åˆ†ææ—¥ä»˜: {previous_date}")

            # åˆ†æçµæœèª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ
            if latest_date:
                results = loader.load_analysis_results(latest_date)
                if results:
                    logger.info(f"åˆ†æçµæœèª­ã¿è¾¼ã¿æˆåŠŸ: {len(results)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿")
                else:
                    logger.warning("åˆ†æçµæœã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")

        # ãƒ‡ãƒ¼ã‚¿æ§‹é€ æ¤œè¨¼ãƒ†ã‚¹ãƒˆ
        test_data, _ = create_test_data()
        entity_metrics = loader.extract_entity_metrics(test_data)
        logger.info(f"ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æŒ‡æ¨™æŠ½å‡º: {len(entity_metrics)}ä»¶")

        logger.info("S3DataLoaderãƒ†ã‚¹ãƒˆå®Œäº†")
        return True

    except Exception as e:
        logger.error(f"S3DataLoaderãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return False


def test_simple_posting_system():
    """SimplePostingSystemï¼ˆS3DataLoaderçµ±åˆç‰ˆï¼‰ã®ãƒ†ã‚¹ãƒˆ"""
    logger.info("=== SimplePostingSystemãƒ†ã‚¹ãƒˆé–‹å§‹ ===")

    try:
        # SimplePostingSystemã‚’åˆæœŸåŒ–
        posting_system = SimplePostingSystem(storage_mode="auto")

        # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã®ç¢ºèª
        status = posting_system.get_system_status()
        logger.info(f"ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹: {status}")

        # åˆ©ç”¨å¯èƒ½æ—¥ä»˜ã®å–å¾—
        available_dates = posting_system.get_available_dates()
        logger.info(f"åˆ©ç”¨å¯èƒ½æ—¥ä»˜æ•°: {len(available_dates)}")

        if available_dates:
            # æœ€æ–°ã®åˆ†æçµæœã®å¤‰åŒ–ã‚’æ¤œçŸ¥ã—ã¦æŠ•ç¨¿ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
            logger.info("æœ€æ–°åˆ†æçµæœã®å¤‰åŒ–æ¤œçŸ¥ãƒ»æŠ•ç¨¿ãƒ†ã‚¹ãƒˆé–‹å§‹")
            result = posting_system.post_latest_changes(force_post=False)

            logger.info(f"æŠ•ç¨¿çµæœ: {result}")

            if result.get("success"):
                if result.get("posted"):
                    logger.info("æŠ•ç¨¿ãŒå®Ÿè¡Œã•ã‚Œã¾ã—ãŸ")
                else:
                    logger.info("å¤‰åŒ–ãŒæ¤œçŸ¥ã•ã‚Œãªã‹ã£ãŸãŸã‚æŠ•ç¨¿ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸ")
            else:
                logger.warning(f"æŠ•ç¨¿å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {result.get('error')}")

        # æŒ‡å®šæ—¥ä»˜ã§ã®æŠ•ç¨¿ãƒ†ã‚¹ãƒˆï¼ˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
        logger.info("æŒ‡å®šæ—¥ä»˜ã§ã®æŠ•ç¨¿ãƒ†ã‚¹ãƒˆé–‹å§‹")
        test_data, previous_data = create_test_data()

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ç›´æ¥ä½¿ç”¨ã—ã¦æŠ•ç¨¿ãƒ†ã‚¹ãƒˆ
        result = posting_system.post_changes(
            previous_data=previous_data,
            current_data=test_data,
            analysis_date=datetime.now().strftime("%Y%m%d"),
            force_post=True
        )

        logger.info(f"ãƒ†ã‚¹ãƒˆæŠ•ç¨¿çµæœ: {result}")

        logger.info("SimplePostingSystemãƒ†ã‚¹ãƒˆå®Œäº†")
        return True

    except Exception as e:
        logger.error(f"SimplePostingSystemãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return False


def test_integrated_posting_system():
    """IntegratedPostingSystemã®ãƒ†ã‚¹ãƒˆ"""
    logger.info("=== IntegratedPostingSystemãƒ†ã‚¹ãƒˆé–‹å§‹ ===")

    try:
        # IntegratedPostingSystemã‚’åˆæœŸåŒ–
        posting_system = IntegratedPostingSystem(storage_mode="auto")

        # æœ€æ–°ã®åˆ†æçµæœã®å¤‰åŒ–ã‚’æ¤œçŸ¥ã—ã¦æŠ•ç¨¿ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
        logger.info("æœ€æ–°åˆ†æçµæœã®å¤‰åŒ–æ¤œçŸ¥ãƒ»æŠ•ç¨¿ãƒ†ã‚¹ãƒˆé–‹å§‹")
        result = posting_system.post_latest_changes(force_post=False)

        logger.info(f"æŠ•ç¨¿çµæœ: {result}")

        if result.get("success"):
            if result.get("posted"):
                logger.info("æŠ•ç¨¿ãŒå®Ÿè¡Œã•ã‚Œã¾ã—ãŸ")
            else:
                logger.info("å¤‰åŒ–ãŒæ¤œçŸ¥ã•ã‚Œãªã‹ã£ãŸãŸã‚æŠ•ç¨¿ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸ")
        else:
            logger.warning(f"æŠ•ç¨¿å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {result.get('error')}")

        logger.info("IntegratedPostingSystemãƒ†ã‚¹ãƒˆå®Œäº†")
        return True

    except Exception as e:
        logger.error(f"IntegratedPostingSystemãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return False


def test_x_api_connection():
    """X APIæ¥ç¶šãƒ†ã‚¹ãƒˆ"""
    logger.info("=== X APIæ¥ç¶šãƒ†ã‚¹ãƒˆé–‹å§‹ ===")

    try:
        # SimplePostingSystemã‚’åˆæœŸåŒ–
        posting_system = SimplePostingSystem()

        # X APIæ¥ç¶šãƒ†ã‚¹ãƒˆ
        result = posting_system.test_connection()

        if result.get("success"):
            logger.info("X APIæ¥ç¶šãƒ†ã‚¹ãƒˆæˆåŠŸ")
            user_info = result.get("user_info")
            if user_info:
                logger.info(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±: {user_info}")
        else:
            logger.warning(f"X APIæ¥ç¶šãƒ†ã‚¹ãƒˆå¤±æ•—: {result.get('error')}")

        logger.info("X APIæ¥ç¶šãƒ†ã‚¹ãƒˆå®Œäº†")
        return True

    except Exception as e:
        logger.error(f"X APIæ¥ç¶šãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return False


def test_data_comparison():
    """ãƒ‡ãƒ¼ã‚¿æ¯”è¼ƒæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    logger.info("=== ãƒ‡ãƒ¼ã‚¿æ¯”è¼ƒæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆé–‹å§‹ ===")

    try:
        loader = S3DataLoader()

        # åˆ©ç”¨å¯èƒ½æ—¥ä»˜ã‚’å–å¾—
        available_dates = loader.list_available_dates()

        if len(available_dates) >= 2:
            # æœ€æ–°ã®2ã¤ã®æ—¥ä»˜ã§æ¯”è¼ƒãƒ†ã‚¹ãƒˆ
            latest_date = max(available_dates)
            previous_date = sorted(available_dates)[-2]

            logger.info(f"æ¯”è¼ƒãƒ†ã‚¹ãƒˆ: {previous_date} â†’ {latest_date}")

            # æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            comparison_data = loader.load_comparison_data(latest_date)

            if comparison_data:
                logger.info("æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«æˆåŠŸ")

                # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æŒ‡æ¨™ã‚’æŠ½å‡º
                if comparison_data.get("previous"):
                    previous_metrics = loader.extract_entity_metrics(comparison_data["previous"])
                    logger.info(f"å‰å›æŒ‡æ¨™æ•°: {len(previous_metrics)}")

                if comparison_data.get("current"):
                    current_metrics = loader.extract_entity_metrics(comparison_data["current"])
                    logger.info(f"ä»Šå›æŒ‡æ¨™æ•°: {len(current_metrics)}")
            else:
                logger.warning("æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—")
        else:
            logger.info("æ¯”è¼ƒãƒ†ã‚¹ãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")

        logger.info("ãƒ‡ãƒ¼ã‚¿æ¯”è¼ƒæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆå®Œäº†")
        return True

    except Exception as e:
        logger.error(f"ãƒ‡ãƒ¼ã‚¿æ¯”è¼ƒæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return False


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    logger.info("SNSæŠ•ç¨¿æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆé–‹å§‹")

    # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    log_dir = project_root / "logs"
    log_dir.mkdir(exist_ok=True)

    # å„ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
    tests = [
        ("S3DataLoader", test_s3_data_loader),
        ("SimplePostingSystem", test_simple_posting_system),
        ("IntegratedPostingSystem", test_integrated_posting_system),
        ("X APIæ¥ç¶š", test_x_api_connection),
        ("ãƒ‡ãƒ¼ã‚¿æ¯”è¼ƒæ©Ÿèƒ½", test_data_comparison)
    ]

    results = {}

    for test_name, test_func in tests:
        logger.info(f"\n{'='*50}")
        logger.info(f"{test_name}ãƒ†ã‚¹ãƒˆé–‹å§‹")
        logger.info(f"{'='*50}")

        try:
            result = test_func()
            results[test_name] = result
            status = "æˆåŠŸ" if result else "å¤±æ•—"
            logger.info(f"{test_name}ãƒ†ã‚¹ãƒˆ: {status}")
        except Exception as e:
            logger.error(f"{test_name}ãƒ†ã‚¹ãƒˆã§ä¾‹å¤–ãŒç™ºç”Ÿ: {e}")
            results[test_name] = False

    # çµæœã‚µãƒãƒªãƒ¼
    logger.info(f"\n{'='*50}")
    logger.info("ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
    logger.info(f"{'='*50}")

    for test_name, result in results.items():
        status = "æˆåŠŸ" if result else "å¤±æ•—"
        logger.info(f"{test_name}: {status}")

    success_count = sum(results.values())
    total_count = len(results)

    logger.info(f"\nç·åˆçµæœ: {success_count}/{total_count} ãƒ†ã‚¹ãƒˆæˆåŠŸ")

    if success_count == total_count:
        logger.info("ğŸ‰ å…¨ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
    else:
        logger.warning("âš ï¸ ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ")

    logger.info("SNSæŠ•ç¨¿æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆçµ‚äº†")


if __name__ == "__main__":
    main()
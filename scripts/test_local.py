#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã®ãƒã‚¤ã‚¢ã‚¹åˆ†æãƒ†ã‚¹ãƒˆç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Usage:
    python scripts/test_local.py
    python scripts/test_local.py --date 20250624
"""

import os
import sys
import argparse
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

def test_hybrid_data_loader(date: str = "20250624"):
    """HybridDataLoaderã®å‹•ä½œãƒ†ã‚¹ãƒˆ"""

    print("ğŸ” HybridDataLoaderå‹•ä½œãƒ†ã‚¹ãƒˆé–‹å§‹")

    try:
        from src.analysis.hybrid_data_loader import HybridDataLoader

        # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ¼ãƒ‰ã§ãƒ†ã‚¹ãƒˆ
        print("ğŸ“‚ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ...")
        loader_local = HybridDataLoader(storage_mode="local")

        try:
            data = loader_local.load_analysis_results(date)
            print(f"âœ… ãƒ­ãƒ¼ã‚«ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ: {len(data)} é …ç›®")
        except Exception as e:
            print(f"âŒ ãƒ­ãƒ¼ã‚«ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—: {e}")

        # autoãƒ¢ãƒ¼ãƒ‰ã§ãƒ†ã‚¹ãƒˆ
        print("ğŸ”„ autoãƒ¢ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ...")
        loader_auto = HybridDataLoader(storage_mode="auto")

        try:
            data = loader_auto.load_analysis_results(date)
            print(f"âœ… autoèª­ã¿è¾¼ã¿æˆåŠŸ: {len(data)} é …ç›®")
        except Exception as e:
            print(f"âŒ autoèª­ã¿è¾¼ã¿å¤±æ•—: {e}")

        print("âœ… HybridDataLoaderãƒ†ã‚¹ãƒˆå®Œäº†")
        return True

    except ImportError as e:
        print(f"âŒ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return False

def test_bias_analysis_engine(date: str = "20250624"):
    """BiasAnalysisEngineã®å‹•ä½œãƒ†ã‚¹ãƒˆ"""

    print("\nğŸ”¬ BiasAnalysisEngineå‹•ä½œãƒ†ã‚¹ãƒˆé–‹å§‹")

    try:
        from src.analysis.bias_analysis_engine import BiasAnalysisEngine

        # ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–
        engine = BiasAnalysisEngine(storage_mode="local")
        print("âœ… BiasAnalysisEngineåˆæœŸåŒ–å®Œäº†")

        return True

    except ImportError as e:
        print(f"âŒ BiasAnalysisEngineã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return False
    except Exception as e:
        print(f"âŒ BiasAnalysisEngineåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def check_data_availability(date: str = "20250624"):
    """ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª"""

    print(f"\nğŸ“Š ãƒ‡ãƒ¼ã‚¿å­˜åœ¨ç¢ºèª: {date}")

    base_path = f"corporate_bias_datasets/integrated/{date}/"

    files_to_check = [
        "corporate_bias_dataset.json",
        "bias_analysis_results.json",
        "collection_summary.json"
    ]

    for filename in files_to_check:
        filepath = f"{base_path}{filename}"
        if os.path.exists(filepath):
            size = os.path.getsize(filepath)
            print(f"âœ… {filename}: {size:,}ãƒã‚¤ãƒˆ")
        else:
            print(f"âŒ {filename}: è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

def test_multiple_comparison_correction(date: str = "20250702"):
    """å¤šé‡æ¯”è¼ƒè£œæ­£ã®æ¨ªå±•é–‹ãƒ†ã‚¹ãƒˆï¼ˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ»ç›¸å¯¾ãƒã‚¤ã‚¢ã‚¹ãƒ»ç›¸é–¢åˆ†æï¼‰"""
    print("\nğŸ§ª å¤šé‡æ¯”è¼ƒè£œæ­£æ¨ªå±•é–‹ãƒ†ã‚¹ãƒˆé–‹å§‹")
    try:
        from src.analysis.bias_analysis_engine import BiasAnalysisEngine
        engine = BiasAnalysisEngine(storage_mode="local")
        results = engine.analyze_integrated_dataset(date)

        # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒã‚¤ã‚¢ã‚¹åˆ†æ
        ranking = results.get("ranking_bias_analysis", {})
        found_ranking = False
        for cat, subcats in ranking.items():
            for subcat, data in subcats.items():
                # entities['entities']é…ä¸‹ã‚’å‚ç…§
                entities = data.get("entities", {})
                if isinstance(entities, dict) and "entities" in entities:
                    entities = entities["entities"]
                for ent, ent_data in entities.items() if isinstance(entities, dict) else []:
                    sig = ent_data.get("ranking_p_value_corrected")
                    if sig is not None:
                        found_ranking = True
                        assert "correction_method" in ent_data
                        assert "rejected" in ent_data
        assert found_ranking, "ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒã‚¤ã‚¢ã‚¹åˆ†æã§è£œæ­£å¾Œpå€¤ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"

        # ç›¸å¯¾ãƒã‚¤ã‚¢ã‚¹åˆ†æï¼ˆåŒæ§˜ã«entities['entities']å‚ç…§ï¼‰
        relative = results.get("relative_bias_analysis", {})
        found_relative = False
        for cat, subcats in relative.items():
            for subcat, data in subcats.items():
                entities = data.get("entities", {})
                if isinstance(entities, dict) and "entities" in entities:
                    entities = entities["entities"]
                for ent, ent_data in entities.items() if isinstance(entities, dict) else []:
                    sig = ent_data.get("relative_p_value_corrected")
                    if sig is not None:
                        found_relative = True
                        assert "correction_method" in ent_data
                        assert "rejected" in ent_data
        # ç›¸å¯¾ãƒã‚¤ã‚¢ã‚¹åˆ†æã¯æœªå®Ÿè£…ã®å ´åˆã‚‚ã‚ã‚‹ã®ã§ã‚¨ãƒ©ãƒ¼ã«ã—ãªã„

        # ç›¸é–¢åˆ†æï¼ˆåŒæ§˜ã«entities['entities']å‚ç…§ï¼‰
        correlation = results.get("correlation_analysis", {})
        found_corr = False
        for cat, subcats in correlation.items():
            for subcat, data in subcats.items():
                entities = data.get("entities", {})
                if isinstance(entities, dict) and "entities" in entities:
                    entities = entities["entities"]
                for ent, ent_data in entities.items() if isinstance(entities, dict) else []:
                    sig = ent_data.get("correlation_p_value_corrected")
                    if sig is not None:
                        found_corr = True
                        assert "correction_method" in ent_data
                        assert "rejected" in ent_data
        # ç›¸é–¢åˆ†æã‚‚æœªå®Ÿè£…ã®å ´åˆã¯ã‚¨ãƒ©ãƒ¼ã«ã—ãªã„

        print("âœ… å¤šé‡æ¯”è¼ƒè£œæ­£ãƒ†ã‚¹ãƒˆ: OK")
    except Exception as e:
        print(f"âŒ å¤šé‡æ¯”è¼ƒè£œæ­£ãƒ†ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼: {e}")

def test_compare_entity_rankings():
    """
    BiasAnalysisEngine.compare_entity_rankingsã®å‹•ä½œç¢ºèªãƒ†ã‚¹ãƒˆã€‚
    Googleã¨Perplexityã®ãƒ€ãƒŸãƒ¼ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒªã‚¹ãƒˆã‚’æ¯”è¼ƒã—ã€å…¨æŒ‡æ¨™ã‚’å‡ºåŠ›ã€‚
    """
    from src.analysis.bias_analysis_engine import BiasAnalysisEngine
    engine = BiasAnalysisEngine()
    google_ranking = ["AWS", "Google Cloud", "Azure", "Oracle", "IBM"]
    perplexity_ranking = ["Google Cloud", "AWS", "IBM", "Azure", "Oracle"]
    result = engine.compare_entity_rankings(google_ranking, perplexity_ranking, label1="Google", label2="Perplexity")
    print("\n=== compare_entity_rankingsãƒ†ã‚¹ãƒˆçµæœ ===")
    for k, v in result.items():
        print(f"{k}: {v}")

def test_ranking_stability_quality_multi():
    """
    è¤‡æ•°å›å®Ÿè¡Œæ™‚ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°å®‰å®šæ€§ãƒ»å“è³ªåˆ†æã®å‡ºåŠ›ä¾‹ãƒ†ã‚¹ãƒˆã€‚
    2å›ä»¥ä¸Šã®all_ranksã‚’æŒã¤ãƒ€ãƒŸãƒ¼detailsã§BiasAnalysisEngine._calculate_ranking_stabilityã¨_calculate_ranking_qualityã‚’æ¤œè¨¼ã€‚
    """
    from src.analysis.bias_analysis_engine import BiasAnalysisEngine
    engine = BiasAnalysisEngine()
    # ãƒ€ãƒŸãƒ¼details: 3å›åˆ†ã®é †ä½
    details = {
        "AWS": {"all_ranks": [1, 1, 1], "official_url": "https://aws.amazon.com", "avg_rank": 1.0},
        "Google Cloud": {"all_ranks": [2, 2, 3], "official_url": "https://cloud.google.com", "avg_rank": 2.33},
        "Azure": {"all_ranks": [3, 3, 2], "official_url": "https://azure.microsoft.com", "avg_rank": 2.67},
        "Oracle": {"all_ranks": [4, 4, 4], "official_url": "https://oracle.com", "avg_rank": 4.0}
    }
    ranking_summary = {"details": details, "avg_ranking": ["AWS", "Google Cloud", "Azure", "Oracle"]}
    answer_list = [
        {"ranking": ["AWS", "Google Cloud", "Azure", "Oracle"]},
        {"ranking": ["AWS", "Google Cloud", "Azure", "Oracle"]},
        {"ranking": ["AWS", "Azure", "Google Cloud", "Oracle"]}
    ]
    execution_count = 3
    stability = engine._calculate_ranking_stability(ranking_summary, answer_list, execution_count)
    quality = engine._calculate_ranking_quality(ranking_summary, answer_list, execution_count)
    print("\n=== è¤‡æ•°å›å®Ÿè¡Œæ™‚ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°å®‰å®šæ€§ãƒ»å“è³ªåˆ†æãƒ†ã‚¹ãƒˆ ===")
    print("[stability_analysis]")
    for k, v in stability.items():
        print(f"{k}: {v}")
    print("\n[quality_analysis]")
    for k, v in quality.items():
        print(f"{k}: {v}")

def main():
    parser = argparse.ArgumentParser(description='ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ')
    parser.add_argument('--date', default='20250624', help='ãƒ†ã‚¹ãƒˆå¯¾è±¡æ—¥ä»˜ (YYYYMMDD)')

    args = parser.parse_args()

    print("ğŸ§ª ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 50)

    # ãƒ‡ãƒ¼ã‚¿å­˜åœ¨ç¢ºèª
    check_data_availability(args.date)

    # HybridDataLoaderãƒ†ã‚¹ãƒˆ
    loader_ok = test_hybrid_data_loader(args.date)

    # BiasAnalysisEngineãƒ†ã‚¹ãƒˆ
    engine_ok = test_bias_analysis_engine(args.date)

    # å¤šé‡æ¯”è¼ƒè£œæ­£æ¨ªå±•é–‹ãƒ†ã‚¹ãƒˆ
    mcc_ok = test_multiple_comparison_correction(args.date)

    # compare_entity_rankingsãƒ†ã‚¹ãƒˆ
    compare_ok = test_compare_entity_rankings()

    # è¤‡æ•°å›å®Ÿè¡Œæ™‚ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°å®‰å®šæ€§ãƒ»å“è³ªåˆ†æãƒ†ã‚¹ãƒˆ
    stability_quality_ok = test_ranking_stability_quality_multi()

    print("\n" + "=" * 50)
    if loader_ok and engine_ok and mcc_ok and compare_ok and stability_quality_ok:
        print("âœ… å…¨ãƒ†ã‚¹ãƒˆæˆåŠŸï¼")
        sys.exit(0)
    else:
        print("âŒ ä¸€éƒ¨ãƒ†ã‚¹ãƒˆå¤±æ•—")
        sys.exit(1)

if __name__ == '__main__':
    main()